{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Load checkpoint and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# !{sys.executable} -m pip install seaborn"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate,train_test_split\n",
    "import ast\n",
    "from sklearn.linear_model import LinearRegression,Lasso,LassoCV,MultiTaskLassoCV\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "import scipy\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "base_path= '../../../../../../T5 EVO/'\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from sklearn.linear_model import LogisticRegression,LassoCV\n",
    "import random\n",
    "# [x[0] for x in os.walk(base_path)]\n",
    "# input_file_keller_pom = '/local_storage/datasets/farzaneh/openpom/data/curated_datasets/embeddings/pom/keller_pom_embeddings_Apr17.csv'\n",
    "# "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "seed = 2024\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "times=30\n",
    "n_components=20"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print(os.getcwd())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def literal_eval_list(list_string):\n",
    "    list_string_temp=list_string.values.tolist()\n",
    "    list_string_all = []\n",
    "    for value in list_string_temp:\n",
    "        list_string_all.append(ast.literal_eval(value))\n",
    "    \n",
    "    list_numpy = np.asarray(list_string_all)\n",
    "    return list_numpy\n",
    "\n",
    "seed=2024\n",
    "#test\n",
    "#keller_pom_y=literal_eval_list(keller_pom.y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# def average_keller(df):\n",
    "#     df_groupbyCID=df.groupby('CID')[['0.1',\n",
    "#      '1.1',\n",
    "#      '2.1',\n",
    "#      '3.1',\n",
    "#      '4.1',\n",
    "#      '5.1',\n",
    "#      '6.1',\n",
    "#      '7.1',\n",
    "#      '8.1',\n",
    "#      '9.1',\n",
    "#      '10.1',\n",
    "#      '11.1',\n",
    "#      '12.1',\n",
    "#      '13.1',\n",
    "#      '14.1',\n",
    "#      '15.1',\n",
    "#      '16.1',\n",
    "#      '17.1',\n",
    "#      '18.1',\n",
    "#      '19.1',\n",
    "#      '20.1',\n",
    "#      '21.1']].mean().reset_index()\n",
    "\n",
    "#     df_groupbyCID['y'] = df_groupbyCID.loc[:, '0.1':'21.1'].values.tolist()\n",
    "#     df_embeddings=df.drop_duplicates(subset=['CID'])\n",
    "#     df_embeddings=df_embeddings[['CID','embeddings']]\n",
    "#     df_groupbyCID = pd.merge(df_groupbyCID, df_embeddings, on='CID', how='left')\n",
    "#     return df_groupbyCID\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# def average_sagar(df):\n",
    "#     df_groupbyCID=df.groupby('CID')[['0.1',\n",
    "#      '1.1',\n",
    "#      '2.1',\n",
    "#      '3.1',\n",
    "#      '4.1',\n",
    "#      '5.1',\n",
    "#      '6.1',\n",
    "#      '7.1',\n",
    "#      '8.1',\n",
    "#      '9.1',\n",
    "#      '10.1',\n",
    "#      '11.1',\n",
    "#      '12.1',\n",
    "#      '13.1',\n",
    "#      '14.1'\n",
    "#      ]].mean().reset_index()\n",
    "\n",
    "#     df_groupbyCID['y'] = df_groupbyCID.loc[:, '0.1':'14.1'].values.tolist()\n",
    "#     df_embeddings=df.drop_duplicates(subset=['CID'])\n",
    "#     df_embeddings=df_embeddings[['CID','embeddings']]\n",
    "#     df_groupbyCID = pd.merge(df_groupbyCID, df_embeddings, on='CID', how='left')\n",
    "#     return df_groupbyCID"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# def average_keller_subject(df):\n",
    "#     df_groupbyCID=df.groupby(['CID','subject'])[['0.1',\n",
    "#      '1.1',\n",
    "#      '2.1',\n",
    "#      '3.1',\n",
    "#      '4.1',\n",
    "#      '5.1',\n",
    "#      '6.1',\n",
    "#      '7.1',\n",
    "#      '8.1',\n",
    "#      '9.1',\n",
    "#      '10.1',\n",
    "#      '11.1',\n",
    "#      '12.1',\n",
    "#      '13.1',\n",
    "#      '14.1',\n",
    "#      '15.1',\n",
    "#      '16.1',\n",
    "#      '17.1',\n",
    "#      '18.1',\n",
    "#      '19.1',\n",
    "#      '20.1',\n",
    "#      '21.1']].mean().reset_index()\n",
    "\n",
    "#     df_groupbyCID['y'] = df_groupbyCID.loc[:, '0.1':'21.1'].values.tolist()\n",
    "#     df_embeddings=df.drop_duplicates(subset=['CID'])\n",
    "#     df_embeddings=df_embeddings[['CID','embeddings']]\n",
    "#     df_groupbyCID = pd.merge(df_groupbyCID, df_embeddings, on='CID', how='left')\n",
    "#     return df_groupbyCID"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# def average_sagar_subject(df):\n",
    "#     df_groupbyCID=df.groupby(['CID','subject'])[['0.1',\n",
    "#      '1.1',\n",
    "#      '2.1',\n",
    "#      '3.1',\n",
    "#      '4.1',\n",
    "#      '5.1',\n",
    "#      '6.1',\n",
    "#      '7.1',\n",
    "#      '8.1',\n",
    "#      '9.1',\n",
    "#      '10.1',\n",
    "#      '11.1',\n",
    "#      '12.1',\n",
    "#      '13.1',\n",
    "#      '14.1'\n",
    "# ]].mean().reset_index()\n",
    "\n",
    "#     df_groupbyCID['y'] = df_groupbyCID.loc[:, '0.1':'14.1'].values.tolist()\n",
    "#     df_embeddings=df.drop_duplicates(subset=['CID'])\n",
    "#     df_embeddings=df_embeddings[['CID','embeddings']]\n",
    "#     df_groupbyCID = pd.merge(df_groupbyCID, df_embeddings, on='CID', how='left')\n",
    "#     return df_groupbyCID"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "def keep_unique_cids(df):\n",
    "    \n",
    "    df = df.drop_duplicates('CID')\n",
    "    df= df[['CID','embeddings']]\n",
    "    return df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def custom_linear_regression(X,y):\n",
    "    # print(y.shape)\n",
    "    if len(y.shape)>1:\n",
    "        linreg = MultiTaskLassoCV(max_iter=1000,n_alphas=200,random_state=seed,n_jobs=-1)\n",
    "    else:\n",
    "        linreg = LassoCV(max_iter=1000,n_alphas=200,random_state=seed,n_jobs=-1)\n",
    "    \n",
    "    estimator= linreg.fit(X,y)\n",
    "    return estimator"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def metrics_per_descritor(X,y,linreg):\n",
    "    predicted=linreg.predict(X)\n",
    "    mseerrors = []\n",
    "    correlations = []\n",
    "    if len(y.shape)>1:\n",
    "        for i in range(y.shape[1]):\n",
    "            mseerror=mean_squared_error(predicted[:,i],y[:,i])\n",
    "            correlation=scipy.stats.pearsonr(predicted[:,i], y[:,i])\n",
    "            mseerrors.append(mseerror)\n",
    "            correlations.append(correlation)\n",
    "            # print(predicted[:,i], y[:,i])\n",
    "        \n",
    "    else:\n",
    "        mseerror=mean_squared_error(predicted,y)\n",
    "        correlation=scipy.stats.pearsonr(predicted, y)\n",
    "        mseerrors.append(mseerror)\n",
    "        correlations.append(correlation)\n",
    "     # print(predicted[:,i], y[:,i])\n",
    "    \n",
    "    return mseerrors, correlations\n",
    "        # plot()\n",
    "        \n",
    "    \n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# def post_process_results(mserrorrs_corssvalidated,correlations_corssvalidated):\n",
    "#     mserrorrs_corssvalidated_array = np.asarray(mserrorrs_corssvalidated) \n",
    "#     mserrorrs_corssvalidated_mean = mserrorrs_corssvalidated_array.mean(axis=0)\n",
    "#     mserrorrs_corssvalidated_std = mserrorrs_corssvalidated_array.std(axis=0)\n",
    "#     # print(\"correlations_corssvalidated\",np.asarray(correlations_corssvalidated).shape)\n",
    "#     correlations_corssvalidated = np.asarray(correlations_corssvalidated)\n",
    "#     if len(correlations_corssvalidated.shape)==4:\n",
    "#         correlations_corssvalidated = np.moveaxis(correlations_corssvalidated, 0,1)\n",
    "#         # print(\"correlations_corssvalidateds\",correlations_corssvalidated.shape)\n",
    "#         correlations_corssvalidated = np.squeeze(correlations_corssvalidated,2)\n",
    "#     # print(\"correlations_corssvalidatedss\",correlations_corssvalidated.shape)\n",
    "#     statistics_correlations_corssvalidated_array = correlations_corssvalidated[:,:,0]\n",
    "#     pvalues_correlations_corssvalidated_array = correlations_corssvalidated[:,:,1]\n",
    "#     statistics_correlations_corssvalidated_mean = statistics_correlations_corssvalidated_array.mean(axis=0)\n",
    "#     statistics_correlations_corssvalidated_std = statistics_correlations_corssvalidated_array.std(axis=0)\n",
    "\n",
    "#     return mserrorrs_corssvalidated_mean,mserrorrs_corssvalidated_std,statistics_correlations_corssvalidated_mean,statistics_correlations_corssvalidated_std\n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# shapeeee(22,3)\n",
    "# (3,22,2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def post_process_results_df(mserrorrs_corssvalidated,correlations_corssvalidated):\n",
    "    mserrorrs_corssvalidated_array = np.asarray(mserrorrs_corssvalidated) \n",
    "    if len(mserrorrs_corssvalidated_array.shape)==3:\n",
    "        mserrorrs_corssvalidated_array = np.squeeze(mserrorrs_corssvalidated_array,-1)\n",
    "        mserrorrs_corssvalidated_array = np.moveaxis(mserrorrs_corssvalidated_array, 0,1)\n",
    "    # print(mserrorrs_corssvalidated_array.shape,\"shapeeee1\")\n",
    "    \n",
    "    correlations_corssvalidated = np.asarray(correlations_corssvalidated)\n",
    "    if len(correlations_corssvalidated.shape)==4:\n",
    "        correlations_corssvalidated = np.moveaxis(correlations_corssvalidated, 0,1)\n",
    "        # print(\"correlations_corssvalidateds\",correlations_corssvalidated.shape)\n",
    "        correlations_corssvalidated = np.squeeze(correlations_corssvalidated,2)\n",
    "    # print(correlations_corssvalidated.shape,\"shapeeee2\")\n",
    "    statistics_correlations_corssvalidated_array = correlations_corssvalidated[:,:,0]\n",
    "    pvalues_correlations_corssvalidated_array = correlations_corssvalidated[:,:,1]\n",
    "\n",
    "    return mserrorrs_corssvalidated_array,statistics_correlations_corssvalidated_array,pvalues_correlations_corssvalidated_array\n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def pipeline_regression(data_groupbyCID,times,n_components=None,y_i=None):\n",
    "    #Embeddings are representations extracted from MoLformer or Pom\n",
    "    # y are chemical features\n",
    "    mserrorrs_corssvalidated = []\n",
    "    correlations_corssvalidated = []\n",
    "    X=np.asarray(data_groupbyCID.embeddings.values.tolist())\n",
    "    if y_i is not None:\n",
    "        y=np.asarray(data_groupbyCID.y.values.tolist())[:,y_i].reshape(-1,1)\n",
    "    else:\n",
    "       y=np.asarray(data_groupbyCID.y.values.tolist())\n",
    "    for i in range(times):\n",
    "       \n",
    "        # print(\"min\", X.min())\n",
    "        # print(\"max\", X.max())\n",
    "          \n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed+i)  \n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        print(n_components, X_train.shape[1], X_train.shape[0])\n",
    "        if (n_components is not None) and (n_components < X_train.shape[1]) :\n",
    "            pca = PCA(n_components=n_components)\n",
    "            X_train=pca.fit_transform(X_train)\n",
    "            X_test=pca.transform(X_test)\n",
    "        linreg =custom_linear_regression(X_train,y_train)\n",
    "        mseerrors, correlations=metrics_per_descritor(X_test,y_test,linreg)\n",
    "        mserrorrs_corssvalidated.append(mseerrors)\n",
    "        correlations_corssvalidated.append(correlations)\n",
    "    return mserrorrs_corssvalidated, correlations_corssvalidated"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def prepare_dataset(ds):\n",
    "    # ds['y'] = ds['y'].apply(ast.literal_eval)\n",
    "    ds['embeddings'] = ds['embeddings'].apply(ast.literal_eval)\n",
    "\n",
    "    # delete y as perception to not mix that \n",
    "    if 'y' in ds.columns:\n",
    "        del ds['y']\n",
    "    return ds"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def select_features(input_file):\n",
    "    ds_alva = pd.read_csv(input_file)\n",
    "    ds_alva= ds_alva.rename(columns={\"cid\":\"CID\"})\n",
    "    if 'CID' not in ds_alva:\n",
    "        ds_alva=ds_alva.rename(columns={\"Unnamed: 0\": \"CID\"})\n",
    "        # ds_alva = ds_alva.reindex(columns=['CID'])\n",
    "        index_columns = ds_alva.columns.tolist()  # All columns except the last one (NewIndex)\n",
    "\n",
    "        # ds_alva = ds_alva.set_index(['CID'] + index_columns)\n",
    "\n",
    "    # if chemical_features_r is None: \n",
    "    chemical_features_r=[\"nCIR\",\n",
    "                     \"ZM1\", \n",
    "                     \"GNar\", \n",
    "                     \"S1K\", \n",
    "                     \"piPC08\",\n",
    "                     \"MATS1v\",\n",
    "                     \"MATS7v\",\n",
    "                     \"GATS1v\", \n",
    "                     \"Eig05_AEA(bo)\", \n",
    "                     \"SM02_AEA(bo)\",\n",
    "                     \"SM03_AEA(dm)\",\n",
    "                     \"SM10_AEA(dm)\",\n",
    "                     \"SM13_AEA(dm)\",\n",
    "                      \"SpMin3_Bh(v)\",\n",
    "                     \"RDF035v\",\n",
    "                     \"G1m\",\n",
    "                     \"G1v\",\n",
    "                     \"G1e\",\n",
    "                     \"G3s\",\n",
    "                     \"R8u+\",\n",
    "                     \"nRCOSR\"]\n",
    "\n",
    "    nonStereoSMILE = list(map(lambda x: \"nonStereoSMILES___\" + x, chemical_features_r))\n",
    "    # IsomericSMILES = list(map(lambda x: \"IsomericSMILES___\" + x, chemical_features_r))\n",
    "    selected_features = nonStereoSMILE\n",
    "    features= ['CID','nonStereoSMILES']+selected_features\n",
    "    print(features)\n",
    "    ds_alva.set_index(['CID'] + features)\n",
    "    # print(\"cc1\", ds_alva.columns.values.tolist())\n",
    "    \n",
    "    # print(\"cc2\", ds_alva.columns.values.tolist())\n",
    "    ds_alva_selected = ds_alva[features]\n",
    "    ds_alva_selected = ds_alva_selected.fillna(0)\n",
    "    ds_alva_selected['y'] = ds_alva_selected[selected_features].values.tolist()\n",
    "    return ds_alva_selected,nonStereoSMILE"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "def min_max_extraction(data_groupbyCID,times,y_i=None):\n",
    "    min_max_dfs = []\n",
    "    X=np.asarray(data_groupbyCID.embeddings.values.tolist())\n",
    "    if y_i is not None:\n",
    "        y=np.asarray(data_groupbyCID.y.values.tolist())[:,y_i].reshape(-1,1)\n",
    "    else:\n",
    "       y=np.asarray(data_groupbyCID.y.values.tolist())\n",
    "    for i in range(times):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed+i)  \n",
    "        # print(X_train.shape,\"x shape\")\n",
    "        # print(y_train.shape,\"y shape\")\n",
    "        df = pd.DataFrame(y_test)\n",
    "\n",
    "        # Step 3: Extract the min and max values for each column\n",
    "        min_values = df.min()\n",
    "        max_values = df.max()\n",
    "\n",
    "       # Create DataFrames for min and max values with an additional column for the label\n",
    "        min_df = pd.DataFrame(min_values).T\n",
    "        min_df['Type'] = 'Min'\n",
    "    \n",
    "        max_df = pd.DataFrame(max_values).T\n",
    "        max_df['Type'] = 'Max'\n",
    "    \n",
    "        # Concatenate the min and max DataFrames\n",
    "        min_max_df = pd.concat([min_df, max_df])\n",
    "        min_max_df['Dataset'] = i\n",
    "    \n",
    "        # Append the concatenated DataFrame to the lis\n",
    "    \n",
    "        # Append the min_max_df to the list\n",
    "        min_max_dfs.append(min_max_df)\n",
    "    \n",
    "    final_df = pd.concat(min_max_dfs)   \n",
    "        # Step 4: Create a new DataFrame with the min and max values per column\n",
    "    final_df.set_index(['Dataset', 'Type'], inplace=True)\n",
    "    # min_max_df = pd.DataFrame([min_values, max_values], index=['Min', 'Max'])\n",
    "        \n",
    "    return final_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def pipeline(model_name,input_file_alva,input_file,times=30,n_components=None,ds=\"keller\",per_descritor=False,count=False):\n",
    "    # input_file_keller = base_path+'openpom/data/curated_datasets/embeddings/molformer/keller_molformer_embeddings_13_Apr17.csv'\n",
    "    df=pd.read_csv(input_file)\n",
    "    df=prepare_dataset(df)\n",
    "   \n",
    "    \n",
    "    # if ds==\"keller\":\n",
    "    #     # df_groupbyCID=average_keller(df)\n",
    "    #     # df_groupbyCIDSubject=average_keller_subject(df)\n",
    "    #     df_uniqe_cids= keep_unique_cids(df,'0.1','14.1')\n",
    "    # elif ds==\"sagar\":\n",
    "    #     # df_groupbyCID=average_sagar(df)\n",
    "    #     # df_groupbyCIDSubject=average_sagar_subject(df)\n",
    "    \n",
    "    df_uniqe_cids= keep_unique_cids(df)\n",
    "   \n",
    "    \n",
    "    df_alva,features = select_features(input_file_alva)\n",
    "    \n",
    "    df_groupbyCID= pd.merge(df_alva,df_uniqe_cids,on=\"CID\")\n",
    "    # print(len(df_groupbyCID.y.values.tolist()))\n",
    "    # print(np.asarray(df_groupbyCID.y.values.tolist()).shape)\n",
    "    \n",
    "\n",
    "    # print(features)\n",
    "    # features  =  df_groupbyCID.columns.values.tolist()[1:-2]\n",
    "    # print(\"descriptors\",descriptors)\n",
    "    if per_descritor : \n",
    "        mserrorrs_df_corssvalidated =[]\n",
    "        correlations_df_corssvalidated=[]\n",
    "        # pass\n",
    "        for i,feature in enumerate(features):\n",
    "            # print(\"i\",i,feature)\n",
    "            # print(feature)\n",
    "            # print(groupbyCID_selected.columns.values.tolist())\n",
    "            groupbyCID_selected = df_groupbyCID[[\"CID\",\"y\",\"embeddings\",feature]]\n",
    "            mserrorr_df_corssvalidated, correlation_df_corssvalidated=pipeline_regression(groupbyCID_selected,times=times,n_components=n_components,y_i = i)\n",
    "            mserrorrs_df_corssvalidated.append(mserrorr_df_corssvalidated)\n",
    "            # print(mserrorr_df_corssvalidated)\n",
    "            correlations_df_corssvalidated.append(correlation_df_corssvalidated)\n",
    "            # print(\"i\",i)\n",
    "            \n",
    "    else:\n",
    "        if count:\n",
    "            min_max_df=min_max_extraction(df_groupbyCID,times)\n",
    "            return min_max_df\n",
    "        else:\n",
    "        \n",
    "            mserrorrs_df_corssvalidated, correlations_df_corssvalidated=pipeline_regression(df_groupbyCID,times=times,n_components=n_components)\n",
    "    # print((mserrorrs_df_corssvalidated),\"shape\")    \n",
    "    # mserrorrs_mean_df,mserrorrs_std_df,correlations_mean_df,correlations_std_df =post_process_results(mserrorrs_df_corssvalidated, correlations_df_corssvalidated)\n",
    "    \n",
    "    mserrorrs_corssvalidated_df,statistics_correlations_corssvalidated_df,pvalues_correlations_corssvalidated_df=post_process_results_df(mserrorrs_df_corssvalidated, correlations_df_corssvalidated)\n",
    "    df_df_mse= pd.DataFrame(mserrorrs_corssvalidated_df)\n",
    "    # df_df_mse = df_df_mse.T\n",
    "    df_df_mse['model'] = model_name\n",
    "    df_df_cor= pd.DataFrame(statistics_correlations_corssvalidated_df)\n",
    "    df_df_cor['model'] = model_name\n",
    "    # df_keller = pd.concat((df_keller_molformer,df_keller_pom))\n",
    "    return df_df_mse, df_df_cor"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "source": [
    "def pipeline_multipleds(model_name,input_file_alvas,input_files,times=30,n_components=None,ds=\"keller\",per_descritor=False,count=False):\n",
    "    # input_file_keller = base_path+'openpom/data/curated_datasets/embeddings/molformer/keller_molformer_embeddings_13_Apr17.csv'\n",
    "    df_list = []\n",
    "    for input_file,input_file_alva in zip(input_files, input_file_alvas):\n",
    "        print(input_file)\n",
    "        print(input_file_alva)\n",
    "        df=pd.read_csv(input_file)\n",
    "        df=prepare_dataset(df)  \n",
    "        df_uniqe_cids= keep_unique_cids(df)\n",
    "        df_alva,features = select_features(input_file_alva)    \n",
    "        df_groupbyCID= pd.merge(df_alva,df_uniqe_cids,on=\"CID\")\n",
    "        df_list.append(df_groupbyCID)\n",
    "    \n",
    "\n",
    "    result_df = pd.concat(df_list, ignore_index=True)\n",
    "    result_df = result_df.drop_duplicates('nonStereoSMILES')\n",
    "    \n",
    "    if count:\n",
    "        min_max_df=min_max_extraction(df_groupbyCID,times)\n",
    "        return min_max_df\n",
    "    else:\n",
    "        \n",
    "        mserrorrs_df_corssvalidated, correlations_df_corssvalidated=pipeline_regression(result_df,times=times,n_components=n_components)\n",
    "        \n",
    "    \n",
    "    mserrorrs_corssvalidated_df,statistics_correlations_corssvalidated_df,pvalues_correlations_corssvalidated_df=post_process_results_df(mserrorrs_df_corssvalidated, correlations_df_corssvalidated)\n",
    "    df_df_mse= pd.DataFrame(mserrorrs_corssvalidated_df)\n",
    "    # df_df_mse = df_df_mse.T\n",
    "    df_df_mse['model'] = model_name\n",
    "    df_df_cor= pd.DataFrame(statistics_correlations_corssvalidated_df)\n",
    "    df_df_cor['model'] = model_name\n",
    "    # df_keller = pd.concat((df_keller_molformer,df_keller_pom))\n",
    "    return df_df_mse, df_df_cor"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# corrs_molfomer,mses_molformer,df_keller_cor_pom,df_keller_mse_pom,df_keller_cor_alva,df_keller_mse_alva =compute_correlation_keller(3 , 2, 2024,per_descritor=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def compute_correlation_sagar(times , n_components,per_descritor=False):\n",
    "    # input_file_sagar_molformer = base_path+'alignment_olfaction_datasets/data/curated_datasets/embeddings/molformer/sagar_molformer_embeddings_13_Apr17.csv'\n",
    "    # df_sagar_mse_molformer, df_sagar_cor_molformer = pipeline('molformer',input_file_sagar_molformer,times=times,n_components=n_components,seed=seed,ds=\"sagar\")\n",
    "\n",
    "\n",
    "    input_file_sagar_alva = base_path+'alignment_olfaction_datasets/data/curated_datasets/alva/sagar_molecules_alva_17Apr.csv'\n",
    "    \n",
    "    # df_sagar_mse_alva, df_sagar_cor_alva = pipeline('alva',input_file_sagar_pom,input_file_sagar_alva,times=times,n_components=n_components,ds=\"sagar\")\n",
    "\n",
    "    \n",
    "    input_file_sagar_pom = base_path+'alignment_olfaction_datasets/data/curated_datasets/embeddings/pom/sagar_pom_embeddings_Apr17.csv'\n",
    "    df_sagar_mse_pom, df_sagar_cor_pom = pipeline('pom',input_file_sagar_alva,input_file_sagar_pom,times=times,n_components=n_components,ds=\"sagar\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    corrs_molformer=[]\n",
    "\n",
    "    mses_molformer=[]\n",
    "    \n",
    "    for i in [0,1,2,3,4,5,6,7,8,9,10,11,13]:\n",
    "        input_file_sagar_molformer = base_path+'alignment_olfaction_datasets/data/curated_datasets/embeddings/molformer/sagar_molformer_embeddings_'+str(i)+'_Apr17.csv'\n",
    "        df_sagar_mse_molformer, df_sagar_cor_molformer = pipeline('molformer',input_file_sagar_alva,input_file_sagar_molformer,times=times,n_components=n_components,ds=\"sagar\",per_descritor=per_descritor)\n",
    "        \n",
    "        \n",
    "        \n",
    "        corrs_molformer.append(df_sagar_cor_molformer)\n",
    "        mses_molformer.append(df_sagar_mse_molformer)\n",
    "\n",
    "    return corrs_molformer,mses_molformer,df_sagar_cor_pom,df_sagar_mse_pom"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def compute_correlation_keller(times , n_components,per_descritor=False):\n",
    "\n",
    "\n",
    "    input_file_keller_alva = base_path+'alignment_olfaction_datasets/data/curated_datasets/alva/keller_molecules_alva_17Apr.csv'\n",
    "\n",
    "    \n",
    "    input_file_keller_pom = base_path+'alignment_olfaction_datasets/data/curated_datasets/embeddings/pom/keller_pom_embeddings_Apr17.csv'\n",
    "    df_keller_mse_pom, df_keller_cor_pom = pipeline('pom',input_file_keller_alva,input_file_keller_pom,times=times,n_components=n_components)\n",
    "    \n",
    "    \n",
    "    # df_keller_mse_alva, df_keller_cor_alva = pipeline('alva',input_file_keller_alva,input_file_keller_pom,input_file_keller_alva,times=times,n_components=n_components)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    corrs_molformer=[]\n",
    "\n",
    "    mses_molformer=[]\n",
    "    \n",
    "    for i in [0,1,2,3,4,5,6,7,8,9,10,11,13]:\n",
    "    # for i in [0,13]:\n",
    "        input_file_keller_molformer = base_path+'alignment_olfaction_datasets/data/curated_datasets/embeddings/molformer/keller_molformer_embeddings_'+str(i)+'_Apr17.csv'\n",
    "        df_keller_mse_molformer, df_keller_cor_molformer = pipeline('molformer',input_file_keller_alva,input_file_keller_molformer,times=times,n_components=n_components,per_descritor=per_descritor)\n",
    "        \n",
    "        \n",
    "        \n",
    "        corrs_molformer.append(df_keller_cor_molformer)\n",
    "        mses_molformer.append(df_keller_mse_molformer)\n",
    "\n",
    "    return corrs_molformer,mses_molformer,df_keller_cor_pom,df_keller_mse_pom"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "def count_df_x_keller(times ,per_descritor=False,ds=\"keller\"):\n",
    "    if ds == 'all':\n",
    "        pipeline_func = pipeline_multipleds\n",
    "        input_file_alva=[]\n",
    "        input_file_pom=[]\n",
    "        \n",
    "        \n",
    "\n",
    "        for ds_name in ['snitz','keller','ravia','sagar', 'gslf']:\n",
    "        # for ds in ['ravia','sagar']:\n",
    "            input_file_alva.append(base_path+'alignment_olfaction_datasets/data/curated_datasets/alva/'+ds_name+'_molecules_alva_17Apr.csv')\n",
    "       \n",
    "            input_file_pom.append(base_path+'alignment_olfaction_datasets/data/curated_datasets/embeddings/pom/'+ds_name+'_pom_embeddings_Apr17.csv')\n",
    "    else:\n",
    "        ds_name = ds\n",
    "        pipeline_func = pipeline\n",
    "\n",
    "        input_file_alva = base_path+'alignment_olfaction_datasets/data/curated_datasets/alva/'+ds_name+'_molecules_alva_17Apr.csv'\n",
    "    \n",
    "        \n",
    "        input_file_pom = base_path+'alignment_olfaction_datasets/data/curated_datasets/embeddings/pom/'+ds_name+'_pom_embeddings_Apr17.csv'\n",
    "\n",
    "    \n",
    "    min_max_df = pipeline_func('pom',input_file_alva,input_file_pom,times=times,n_components=n_components,count=True)\n",
    "    return min_max_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "# df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "def compute_correlation(ds,times , n_components,per_descritor=False):\n",
    "\n",
    "    if ds == 'all':\n",
    "        pipeline_func = pipeline_multipleds\n",
    "        input_file_alva=[]\n",
    "        input_file_pom=[]\n",
    "        \n",
    "        \n",
    "\n",
    "        for ds_name in ['snitz','keller','ravia','sagar', 'gslf']:\n",
    "        # for ds in ['ravia','sagar']:\n",
    "            input_file_alva.append(base_path+'alignment_olfaction_datasets/data/curated_datasets/alva/'+ds_name+'_molecules_alva_17Apr.csv')\n",
    "       \n",
    "            input_file_pom.append(base_path+'alignment_olfaction_datasets/data/curated_datasets/embeddings/pom/'+ds_name+'_pom_embeddings_Apr17.csv')\n",
    "    else:\n",
    "        ds_name = ds\n",
    "        pipeline_func = pipeline\n",
    "\n",
    "        input_file_alva = base_path+'alignment_olfaction_datasets/data/curated_datasets/alva/'+ds_name+'_molecules_alva_17Apr.csv'\n",
    "    \n",
    "        \n",
    "        input_file_pom = base_path+'alignment_olfaction_datasets/data/curated_datasets/embeddings/pom/'+ds_name+'_pom_embeddings_Apr17.csv'\n",
    "\n",
    "    \n",
    "    df_mse_pom, df_cor_pom = pipeline_func('pom',input_file_alva,input_file_pom,times=times,n_components=n_components)\n",
    "    \n",
    "    \n",
    "    # df_keller_mse_alva, df_keller_cor_alva = pipeline('alva',input_file_keller_alva,input_file_keller_pom,input_file_keller_alva,times=times,n_components=n_components)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    corrs_molformer=[]\n",
    "\n",
    "    mses_molformer=[]\n",
    "    \n",
    "    for i in [0,1,2,3,4,5,6,7,8,9,10,11,13]:\n",
    "    # for i in [0,13]:\n",
    "        input_file_molformer=[]\n",
    "        if ds=='all':\n",
    "            for ds_name in ['keller','ravia','sagar','snitz', 'gslf']:\n",
    "                input_file_molformer.append(base_path+'alignment_olfaction_datasets/data/curated_datasets/embeddings/molformer/'+ds_name+'_molformer_embeddings_'+str(i)+'_Apr17.csv')\n",
    "        else:\n",
    "            input_file_molformer = base_path+'alignment_olfaction_datasets/data/curated_datasets/embeddings/molformer/'+ds_name+'_molformer_embeddings_'+str(i)+'_Apr17.csv'\n",
    "        df_mse_molformer, df_cor_molformer = pipeline_func('molformer',input_file_alva,input_file_molformer,times=times,n_components=n_components,per_descritor=per_descritor)\n",
    "        \n",
    "        \n",
    "        \n",
    "        corrs_molformer.append(df_cor_molformer)\n",
    "        mses_molformer.append(df_mse_molformer)\n",
    "\n",
    "    return corrs_molformer,mses_molformer,df_cor_pom,df_mse_pom"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Extracting Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "def post_process_tocsv(corrs,tasks):\n",
    "    corrs[0][\"layer\"]=0\n",
    "    corrss = corrs[0]\n",
    "    for i in range(1,13):\n",
    "        corrs[i][\"layer\"] = i\n",
    "        corrss  = pd.concat([corrss, corrs[i]])\n",
    "    del corrss['model']\n",
    "    corrss.columns = tasks+[\"layer\"]    \n",
    "    corrss['model']='molformer'\n",
    "    return corrss"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "chemical_features_r=[\"nCIR\",\n",
    "                     \"ZM1\", \n",
    "                     \"GNar\", \n",
    "                     \"S1K\", \n",
    "                     \"piPC08\",\n",
    "                     \"MATS1v\",\n",
    "                     \"MATS7v\",\n",
    "                     \"GATS1v\", \n",
    "                     \"Eig05_AEA(bo)\", \n",
    "                     \"SM02_AEA(bo)\",\n",
    "                     \"SM03_AEA(dm)\",\n",
    "                     \"SM10_AEA(dm)\",\n",
    "                     \"SM13_AEA(dm)\",\n",
    "                      \"SpMin3_Bh(v)\",\n",
    "                     \"RDF035v\",\n",
    "                     \"G1m\",\n",
    "                     \"G1v\",\n",
    "                     \"G1e\",\n",
    "                     \"G3s\",\n",
    "                     \"R8u+\",\n",
    "                     \"nRCOSR\"]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Keller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# corrs_molfomer,mses_molformer,df_keller_cor_pom,df_keller_mse_pom =compute_correlation_keller(times , n_components,per_descritor=False)\n",
    "corrs_molfomer,mses_molformer,df_keller_cor_pom,df_keller_mse_pom =compute_correlation('keller',times , n_components,per_descritor=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "source": [
    "min_max_df =count_df_x_keller(times ,per_descritor=False,ds=\"keller\")\n",
    "min_max_df.to_csv('keller_min_max_alva.csv', index=True)   "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "source": [
    "df_keller_cor_pom.columns = chemical_features_r+[\"model\"]\n",
    "df_keller_cor_pom.to_csv('df_keller_cor_chemical_pom.csv', index=False)  \n",
    "\n",
    "df_keller_mse_pom.columns  = chemical_features_r+[\"model\"]\n",
    "df_keller_mse_pom.to_csv('df_keller_mse_chemical_pom.csv', index=False)  \n",
    "\n",
    "\n",
    "\n",
    "corrs_molfomer_df = post_process_tocsv(corrs_molfomer,chemical_features_r)\n",
    "corrs_molfomer_df.to_csv('df_keller_corrs_chemical_molfomer.csv', index=False)   \n",
    "\n",
    "mses_molformer_df = post_process_tocsv(mses_molformer,chemical_features_r)\n",
    "mses_molformer_df.to_csv('df_keller_mses_chemical_molfomer.csv', index=False)   "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "source": [
    "# df=pd.read_csv(input_file)\n",
    "# df=prepare_dataset(df)\n",
    "\n",
    "# if ds==\"keller\":\n",
    "#     df_groupbyCID=average_keller(df)\n",
    "#     df_groupbyCIDSubject=average_keller_subject(df)\n",
    "# elif ds==\"sagar\":\n",
    "#     df_groupbyCID=average_sagar(df)\n",
    "#     df_groupbyCIDSubject=average_sagar_subject(df)\n",
    "\n",
    "# df_alva,features = select_features(input_file_alva)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sagar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "corrs_molfomer_sagar,mses_molformer_sagar,df_sagar_cor_pom,df_sagar_mse_pom =compute_correlation('sagar',times , n_components,per_descritor=False)\n",
    "# corrs_molfomer,mses_molformer,df_keller_cor_pom,df_keller_mse_pom =compute_correlation('keller',times , n_components,per_descritor=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "source": [
    "min_max_df =count_df_x_keller(times ,per_descritor=False,ds=\"sagar\")\n",
    "min_max_df.to_csv('sagar_min_max_alva.csv', index=True)   "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# corrs_molfomer.to_csv('corrs_molfomer.csv', index=False)  \n",
    "df_sagar_cor_pom.columns = chemical_features_r+[\"model\"]\n",
    "df_sagar_cor_pom.to_csv('df_sagar_cor_chemical_pom.csv', index=False)  \n",
    "\n",
    "df_sagar_mse_pom.columns  = chemical_features_r+[\"model\"]\n",
    "df_sagar_mse_pom.to_csv('df_sagar_mse_chemical_pom.csv', index=False)  \n",
    "\n",
    "# df_keller_cor_alva.columns = keller_tasks+[\"model\"]\n",
    "# df_keller_cor_alva.to_csv('df_keller_cor_alva.csv', index=False)  \n",
    "\n",
    "# df_keller_mse_alva.columns = keller_tasks+[\"model\"]\n",
    "# df_keller_mse_alva.to_csv('df_keller_mse_alva.csv', index=False)   \n",
    "\n",
    "\n",
    "corrs_molfomer_df = post_process_tocsv(corrs_molfomer_sagar,chemical_features_r)\n",
    "corrs_molfomer_df.to_csv('df_sagar_corrs_chemical_molfomer.csv', index=False)   \n",
    "\n",
    "mses_molformer_df = post_process_tocsv(mses_molformer_sagar,chemical_features_r)\n",
    "mses_molformer_df.to_csv('df_sagar_mses_chemical_molfomer.csv', index=False)   "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Ravia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# corrs_molfomer_ravia,mses_molformer_ravia,df_ravia_cor_pom,df_ravia_mse_pom =compute_correlation(times=times , n_components=n_components,per_descritor=False)\n",
    "corrs_molfomer_ravia,mses_molformer_ravia,df_ravia_cor_pom,df_ravia_mse_pom =compute_correlation('ravia',times , n_components,per_descritor=False)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "source": [
    "# corrs_molfomer.to_csv('corrs_molfomer.csv', index=False)  \n",
    "df_ravia_cor_pom.columns = chemical_features_r+[\"model\"]\n",
    "df_ravia_cor_pom.to_csv('df_ravia_cor_chemical_pom.csv', index=False)  \n",
    "\n",
    "df_ravia_mse_pom.columns  = chemical_features_r+[\"model\"]\n",
    "df_ravia_mse_pom.to_csv('df_ravia_mse_chemical_pom.csv', index=False)  \n",
    "\n",
    "# df_keller_cor_alva.columns = keller_tasks+[\"model\"]\n",
    "# df_keller_cor_alva.to_csv('df_keller_cor_alva.csv', index=False)  \n",
    "\n",
    "# df_keller_mse_alva.columns = keller_tasks+[\"model\"]\n",
    "# df_keller_mse_alva.to_csv('df_keller_mse_alva.csv', index=False)   \n",
    "\n",
    "\n",
    "corrs_molfomer_df = post_process_tocsv(corrs_molfomer_ravia,chemical_features_r)\n",
    "corrs_molfomer_df.to_csv('df_ravia_corrs_chemical_molfomer.csv', index=False)   \n",
    "\n",
    "mses_molformer_df = post_process_tocsv(mses_molformer_ravia,chemical_features_r)\n",
    "mses_molformer_df.to_csv('df_ravia_mses_chemical_molfomer.csv', index=False)   "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "source": [
    "min_max_df =count_df_x_keller(times ,per_descritor=False,ds=\"ravia\")\n",
    "min_max_df.to_csv('ravia_min_max_alva.csv', index=True)   "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Snitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# corrs_molfomer_ravia,mses_molformer_ravia,df_ravia_cor_pom,df_ravia_mse_pom =compute_correlation(times=times , n_components=n_components,per_descritor=False)\n",
    "corrs_molfomer_snitz,mses_molformer_snitz,df_snitz_cor_pom,df_snitz_mse_pom =compute_correlation('snitz',times , n_components,per_descritor=False)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "source": [
    "# corrs_molfomer.to_csv('corrs_molfomer.csv', index=False)  \n",
    "df_snitz_cor_pom.columns = chemical_features_r+[\"model\"]\n",
    "df_snitz_cor_pom.to_csv('df_snitz_cor_chemical_pom.csv', index=False)  \n",
    "\n",
    "df_snitz_mse_pom.columns  = chemical_features_r+[\"model\"]\n",
    "df_snitz_mse_pom.to_csv('df_snitz_mse_chemical_pom.csv', index=False)  \n",
    "\n",
    "\n",
    "corrs_molfomer_df = post_process_tocsv(corrs_molfomer_snitz,chemical_features_r)\n",
    "corrs_molfomer_df.to_csv('df_snitz_corrs_chemical_molfomer.csv', index=False)   \n",
    "\n",
    "mses_molformer_df = post_process_tocsv(mses_molformer_snitz,chemical_features_r)\n",
    "mses_molformer_df.to_csv('df_snitz_mses_chemical_molfomer.csv', index=False)   "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "source": [
    "min_max_df =count_df_x_keller(times ,per_descritor=False,ds=\"snitz\")\n",
    "min_max_df.to_csv('snitz_min_max_alva.csv', index=True)   "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## GS-LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# ds='gslf'\n",
    "# input_file_alva = base_path+'alignment_olfaction_datasets/data/curated_datasets/alva/'+ds+'_molecules_alva_17Apr.csv'\n",
    "# # input_file_pom = base_path+'alignment_olfaction_datasets/data/curated_datasets/embeddings/pom/'+ds+'_pom_embeddings_Apr17.csv'\n",
    "# alva = pd.read_csv(input_file_alva)\n",
    "# alva\n",
    "# # # pom.columns.values.tolist()\n",
    "# # # pom[pom['CID']]\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "source": [
    "# input_file_alva=base_path+'alignment_olfaction_datasets/data/curated_datasets/alva/'+'gslf'+'_molecules_alva_17Apr.csv'\n",
    "\n",
    "\n",
    "# select_features(input_file_alva)[0]\n",
    "# ds_alva\n",
    "\n",
    "# ds_alva=ds_alva.rename(columns={\"Unnamed: 0\": \"CID\"})\n",
    "# ds_alva\n",
    "# # ds_alva = ds_alva.reindex(columns=['CID'])\n",
    "# index_columns = ds_alva.columns.tolist()  # All columns except the last one (NewIndex\n",
    "# index_columns\n",
    "# # Setting the new multi-level index\n",
    "# ds_alva = ds_alva.set_index(index_columns)\n",
    "\n",
    "# # input_file_pom.append(base_path+'alignment_olfaction_datasets/data/curated_datasets/embeddings/pom/'+ds+'_pom_embeddings_Apr17.csv')\n",
    "# # pd.read_csv(input_file_pom[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "corrs_molfomer_gslf,mses_molformer_gslf,df_gslf_cor_pom,df_gslf_mse_pom =compute_correlation('gslf',times , n_components,per_descritor=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "source": [
    "# corrs_molfomer.to_csv('corrs_molfomer.csv', index=False)  \n",
    "df_gslf_cor_pom.columns = chemical_features_r+[\"model\"]\n",
    "df_gslf_cor_pom.to_csv('df_gslf_cor_chemical_pom.csv', index=False)  \n",
    "\n",
    "df_gslf_mse_pom.columns  = chemical_features_r+[\"model\"]\n",
    "df_gslf_mse_pom.to_csv('df_gslf_mse_chemical_pom.csv', index=False)  \n",
    "\n",
    "\n",
    "corrs_molfomer_df = post_process_tocsv(corrs_molfomer_gslf,chemical_features_r)\n",
    "corrs_molfomer_df.to_csv('df_gslf_corrs_chemical_molfomer.csv', index=False)   \n",
    "\n",
    "mses_molformer_df = post_process_tocsv(mses_molformer_gslf,chemical_features_r)\n",
    "mses_molformer_df.to_csv('df_gslf_mses_chemical_molfomer.csv', index=False)   "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "source": [
    "min_max_df =count_df_x_keller(times ,per_descritor=False,ds=\"gslf\")\n",
    "min_max_df.to_csv('gslf_min_max_alva.csv', index=True)   "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "source": [
    "# # pd\n",
    "\n",
    "# input_file_alvas=[]\n",
    "# input_files=[]\n",
    "# # for ds in ['sagar','snitz','keller','ravia', 'gslf']:\n",
    "#         # for ds in ['ravia','sagar']:\n",
    "\n",
    "# ds='sagar'\n",
    "# input_file_alva = base_path+'alignment_olfaction_datasets/data/curated_datasets/alva/'+ds+'_molecules_alva_17Apr.csv'\n",
    "       \n",
    "# input_file = base_path+'alignment_olfaction_datasets/data/curated_datasets/embeddings/pom/'+ds+'_pom_embeddings_Apr17.csv'\n",
    "\n",
    "# # for input_file,input_file_alva in zip(input_files, input_file_alvas):\n",
    "# # print(input_file)\n",
    "# # print(input_file_alva)\n",
    "# df=pd.read_csv(input_file)\n",
    "# df=prepare_dataset(df)  \n",
    "# df_uniqe_cids= keep_unique_cids(df)\n",
    "# df_alva,features = select_features(input_file_alva)    \n",
    "# # print(df_alva)\n",
    "# df_groupbyCID= pd.merge(df_alva,df_uniqe_cids,on=\"CID\")\n",
    "# df_list.append(df_groupbyCID)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "source": [
    "min_max_df =count_df_x_keller(times ,per_descritor=False,ds=\"all\")\n",
    "min_max_df.to_csv('all_min_max_alva.csv', index=True)   "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "source": [
    "corrs_molfomer_all,mses_molformer_all,df_all_cor_pom,df_all_mse_pom =compute_correlation('all',times , n_components,per_descritor=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "source": [
    "df_all_cor_pom.columns = chemical_features_r+[\"model\"]\n",
    "df_all_cor_pom.to_csv('df_all_cor_chemical_pom.csv', index=False)  \n",
    "\n",
    "df_all_mse_pom.columns  = chemical_features_r+[\"model\"]\n",
    "df_all_mse_pom.to_csv('df_all_mse_chemical_pom.csv', index=False)  \n",
    "\n",
    "\n",
    "corrs_molfomer_df = post_process_tocsv(corrs_molfomer_all,chemical_features_r)\n",
    "corrs_molfomer_df.to_csv('df_all_corrs_chemical_molfomer.csv', index=False)   \n",
    "\n",
    "mses_molformer_df = post_process_tocsv(mses_molformer_all,chemical_features_r)\n",
    "mses_molformer_df.to_csv('df_all_mses_chemical_molfomer.csv', index=False)   "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
