{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T13:01:10.548858Z",
     "start_time": "2024-06-05T13:01:10.546196Z"
    }
   },
   "cell_type": "code",
   "source": "# exploring RSA for the Similarity datasets",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T11:16:42.838805Z",
     "start_time": "2024-06-06T11:16:42.832434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = \"/Midgard/home/farzantn/phd/Olfaction/MoLFormer_N2024\"\n",
    "sys.path.append(parent_dir)\n",
    "parent_dir=\"/Midgard/home/farzantn/mambaforge/envs/MolTran_CUDA11_cuda/lib/python3.8\"\n",
    "sys.path.append(parent_dir)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T11:16:42.844932Z",
     "start_time": "2024-06-06T11:16:42.839912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(sys.path)\n",
    "base_dir = '/local_storage/datasets/farzaneh/alignment_olfaction_datasets/'"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Midgard/home/farzantn/phd/Olfaction/MoLFormer_N2024/Notebooks', '/Midgard/home/farzantn/mambaforge/envs/Mol/lib/python38.zip', '/Midgard/home/farzantn/mambaforge/envs/Mol/lib/python3.8', '/Midgard/home/farzantn/mambaforge/envs/Mol/lib/python3.8/lib-dynload', '', '/Midgard/home/farzantn/mambaforge/envs/Mol/lib/python3.8/site-packages', '/Midgard/home/farzantn/mambaforge/envs/Mol/lib/python3.8/site-packages/alvadesccliwrapper-1.0.8-py3.8.egg', '/Midgard/home/farzantn/phd/Olfaction/MoLFormer_N2024', '/Midgard/home/farzantn/mambaforge/envs/MolTran_CUDA11_cuda/lib/python3.8']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T11:16:43.196872Z",
     "start_time": "2024-06-06T11:16:43.193208Z"
    }
   },
   "cell_type": "code",
   "source": "# base_path= '../../../../../../T5 EVO/'",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T11:16:47.190141Z",
     "start_time": "2024-06-06T11:16:43.686047Z"
    }
   },
   "source": [
    "device_name='cuda'\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from argparse import Namespace\n",
    "import yaml\n",
    "print(os.getcwd())\n",
    "print(sys.path)\n",
    "import matplotlib.pyplot as plt\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "# Determine the path to the 'hparams.yaml' file relative to the script's location\n",
    "script_dir = os.getcwd()\n",
    "yaml_path = os.path.join(script_dir, 'custom_utils/hparams.yaml')\n",
    "\n",
    "with open('../custom_utils/hparams.yaml', 'r') as f:\n",
    "    config = Namespace(**yaml.safe_load(f))\n",
    "    \n",
    "from custom_utils.tokenizer.tokenizer import MolTranBertTokenizer\n",
    "from custom_utils.train_pubchem_light import LightningModule\n",
    "\n",
    "# from utils.util_alignment import *\n",
    "from utils.prepare_datasets import *\n",
    "from utils.custom_models import *\n",
    "\n",
    "from constants import gs_lf_tasks\n",
    "\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "from custom_utils.data_utils import get_class_imbalance_ratio\n",
    "# \n",
    "\n",
    "# # from train_pubchem_light import LightningModule\n",
    "\n",
    "# import seaborn as sns"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Midgard/home/farzantn/phd/Olfaction/MoLFormer_N2024/Notebooks\n",
      "['/Applications/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug', '/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev', '/Midgard/home/farzantn/phd/Olfaction/MoLFormer_N2024/Notebooks', '/Midgard/home/farzantn/mambaforge/envs/Mol/lib/python38.zip', '/Midgard/home/farzantn/mambaforge/envs/Mol/lib/python3.8', '/Midgard/home/farzantn/mambaforge/envs/Mol/lib/python3.8/lib-dynload', '', '/Midgard/home/farzantn/mambaforge/envs/Mol/lib/python3.8/site-packages', '/Midgard/home/farzantn/mambaforge/envs/Mol/lib/python3.8/site-packages/alvadesccliwrapper-1.0.8-py3.8.egg', '/Midgard/home/farzantn/phd/Olfaction/MoLFormer_N2024', '/Midgard/home/farzantn/mambaforge/envs/MolTran_CUDA11_cuda/lib/python3.8']\n",
      "/Midgard/home/farzantn/phd/Olfaction/MoLFormer_N2024/Notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/Midgard/home/farzantn/mambaforge/envs/Mol/lib/python3.8/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T11:16:47.195850Z",
     "start_time": "2024-06-06T11:16:47.192348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"font.size\"] = 25\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "plt.rc('font',**{'family':'serif','serif':['Times']})"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading MolFormer Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:04:21.735866Z",
     "start_time": "2024-06-06T12:02:56.217064Z"
    }
   },
   "source": [
    "tokenizer = MolTranBertTokenizer('../custom_utils/tokenizer/bert_vocab.txt')\n",
    "ckpt = '../MoLformer_Pretrained/checkpoints/N-Step-Checkpoint_3_30000.ckpt'\n",
    "lm = LightningModule(config, tokenizer.vocab).load_from_checkpoint(ckpt, config=config, vocab=tokenizer.vocab)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Midgard/home/farzantn/phd/Olfaction/MoLFormer_N2024/Notebooks\n",
      "/Midgard/home/farzantn/phd/Olfaction/MoLFormer_N2024/Notebooks\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Rotation Embedding\n",
      "/Midgard/home/farzantn/phd/Olfaction/MoLFormer_N2024/Notebooks\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 12345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:04:21.742509Z",
     "start_time": "2024-06-06T12:04:21.739060Z"
    }
   },
   "source": [
    "def create_linear_classifier(TASKS, n_classes,dataset):\n",
    "    \n",
    "    n_tasks= len(TASKS)\n",
    "    \n",
    "    #todo change NonLinearModel to LiearModel \n",
    "    model = NonLinearModel(n_tasks).to(device_name)\n",
    "    \n",
    "    # model.n_tasks=n_tasks\n",
    "    model.n_classes=1\n",
    "    train_ratios = get_class_imbalance_ratio(dataset)\n",
    "    # ratios = get_class_imbalance_ratio(train_dataset)\n",
    "    lr = 1e-4\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    modeldeepchem = LinearModelMultiLabelDeepchem(\\\n",
    "        model=model,class_imbalance_ratio=train_ratios,loss_aggr_type='sum',\\\n",
    "        device_name=device_name,mode=model,optimizer_name = 'adam',\\\n",
    "        learning_rate=learning_rate,batch_size=128)\n",
    "    \n",
    "    return modeldeepchem\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:04:21.748758Z",
     "start_time": "2024-06-06T12:04:21.743568Z"
    }
   },
   "source": [
    "def run_linear_classifier(modeldeepchem,embedding_dataset,embedding_test_dataset,metric,metric_str,nb_epoch = 2):\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    train_scores=[]\n",
    "    valid_scores=[]\n",
    "    losses=[]\n",
    "    for epoch in range(1, nb_epoch+1):\n",
    "        loss = modeldeepchem.fit(\n",
    "              embedding_dataset,\n",
    "              nb_epoch=1,\n",
    "              max_checkpoints_to_keep=1,\n",
    "              deterministic=False,\n",
    "              restore=epoch>1)    \n",
    "        losses.append(loss)\n",
    "    \n",
    "    modeldeepchem.save_checkpoint()\n",
    "    return modeldeepchem,train_scores,valid_scores,losses\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:04:21.752625Z",
     "start_time": "2024-06-06T12:04:21.750165Z"
    }
   },
   "source": [
    "def prepare_dataset(ds):\n",
    "    ds['y'] = ds['y'].apply(ast.literal_eval)\n",
    "    ds['embeddings'] = ds['embeddings'].apply(ast.literal_eval)\n",
    "    return ds"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:04:21.755965Z",
     "start_time": "2024-06-06T12:04:21.753519Z"
    }
   },
   "source": [
    "# input_file = '/local_storage/datasets/farzaneh/alignment_olfaction_datasets/curated_datasets/mols_datasets/curated_ravia2020_behavior_similairity.csv'\n",
    "# pd.read_csv(input_file)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading Human Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ravia 2020 Similarity"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:04:21.771678Z",
     "start_time": "2024-06-06T12:04:21.756788Z"
    }
   },
   "source": "df_ravia,df_ravia_similarity_mean, df_ravia_similarity_mean_pivoted=prepare_ravia_or_snitz(dataset='curated_datasets/mols_datasets/curated_ravia2020_behavior_similairity.csv',base_path=base_dir)",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snitz 2013"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:04:21.787243Z",
     "start_time": "2024-06-06T12:04:21.772509Z"
    }
   },
   "source": "df_snitz, df_snitz_mean,df_snitz_mean_pivoted=prepare_ravia_or_snitz(dataset='curated_datasets/mols_datasets/curated_snitz2013.csv',base_path=base_dir)",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting embedding from MoLFormer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting embedding from MoLFormer for GS-LF and training a (Linear?) Layer on that"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:04:21.789905Z",
     "start_time": "2024-06-06T12:04:21.788024Z"
    }
   },
   "source": [
    "# input_file_molformer = base_dir + 'curated_datasets/embeddings/molformer/ravia_molformer_embeddings_13_Apr17.csv'\n",
    "# gs_lf_molformer=pd.read_csv(input_file_molformer)\n",
    "# gs_lf_molformer['embeddings'] = gs_lf_molformer['embeddings'].apply(ast.literal_eval)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:04:21.797883Z",
     "start_time": "2024-06-06T12:04:21.790792Z"
    }
   },
   "source": [
    "input_file_indices = base_dir+'curated_datasets/embeddings/pom/gslf-splits-idx.csv' # or new downloaded file path\n",
    "\n",
    "indices = pd.read_csv(input_file_indices)\n",
    "indices_train = indices.loc[indices['split']=='train']['main_idx'].values.tolist()\n",
    "indices_valid = indices.loc[indices['split']=='valid']['main_idx'].values.tolist()\n",
    "indices_test = indices.loc[indices['split']=='test']['main_idx'].values.tolist()"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:04:31.487773Z",
     "start_time": "2024-06-06T12:04:21.799230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_file_molformer = base_dir+'curated_datasets/embeddings/molformer/gslf_molformer_embeddings_13_Apr17.csv'\n",
    "\n",
    "gs_lf_molformer=pd.read_csv(input_file_molformer)\n",
    "gs_lf_molformer=prepare_dataset(gs_lf_molformer)\n",
    "\n",
    "\n",
    "gs_lf_molformer_np = np.asarray(gs_lf_molformer.embeddings.tolist())\n",
    "gs_lf_molformer_y = np.asarray(gs_lf_molformer.y.tolist())\n",
    "\n",
    "gs_lf_molformer_embeddings_train = gs_lf_molformer_np[indices_train]\n",
    "gs_lf_molformer_y_train = gs_lf_molformer_y[indices_train]\n",
    "\n",
    "gs_lf_molformer_embeddings_test = gs_lf_molformer_np[indices_test]\n",
    "gs_lf_molformer_y_test = gs_lf_molformer_y[indices_test]\n",
    "\n",
    "gs_lf_molformer_embeddings_valid = gs_lf_molformer_np[indices_valid]\n",
    "gs_lf_molformer_y_valid = gs_lf_molformer_y[indices_valid]\n",
    "\n",
    "embedding_train_dataset_gslf = dc.data.DiskDataset.from_numpy(gs_lf_molformer_embeddings_train,gs_lf_molformer_y_train)\n",
    "embedding_test_dataset_gslf = dc.data.DiskDataset.from_numpy(gs_lf_molformer_embeddings_test,gs_lf_molformer_y_test)\n",
    "embedding_valid_dataset_gslf = dc.data.DiskDataset.from_numpy(gs_lf_molformer_embeddings_valid,gs_lf_molformer_y_valid)\n",
    "\n",
    "dataset_gslf = dc.data.DiskDataset.from_numpy(gs_lf_molformer_np,gs_lf_molformer_y)"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:04:37.366337Z",
     "start_time": "2024-06-06T12:04:31.488713Z"
    }
   },
   "source": [
    "\n",
    "modeldeepchem_gslf = create_linear_classifier(gs_lf_tasks, 1,dataset_gslf)\n",
    "metric_gslf = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
    "\n",
    "modeldeepchem_gslf,train_scores_gslf,test_scores_gslf,losses_gslf= run_linear_classifier(modeldeepchem_gslf,embedding_train_dataset_gslf,embedding_test_dataset_gslf,metric_gslf,'roc_auc_score',nb_epoch = 100)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CustomMultiLabelBCEWitLogitsLoss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m modeldeepchem_gslf \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_linear_classifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgs_lf_tasks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mdataset_gslf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m metric_gslf \u001B[38;5;241m=\u001B[39m dc\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mMetric(dc\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mroc_auc_score)\n\u001B[1;32m      4\u001B[0m modeldeepchem_gslf,train_scores_gslf,test_scores_gslf,losses_gslf\u001B[38;5;241m=\u001B[39m run_linear_classifier(modeldeepchem_gslf,embedding_train_dataset_gslf,embedding_test_dataset_gslf,metric_gslf,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mroc_auc_score\u001B[39m\u001B[38;5;124m'\u001B[39m,nb_epoch \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m)\n",
      "Cell \u001B[0;32mIn[15], line 15\u001B[0m, in \u001B[0;36mcreate_linear_classifier\u001B[0;34m(TASKS, n_classes, dataset)\u001B[0m\n\u001B[1;32m     12\u001B[0m lr \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1e-4\u001B[39m\n\u001B[1;32m     14\u001B[0m learning_rate \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.001\u001B[39m\n\u001B[0;32m---> 15\u001B[0m modeldeepchem \u001B[38;5;241m=\u001B[39m \u001B[43mLinearModelMultiLabelDeepchem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43mclass_imbalance_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_ratios\u001B[49m\u001B[43m,\u001B[49m\u001B[43mloss_aggr_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43moptimizer_name\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43madam\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m modeldeepchem\n",
      "File \u001B[0;32m~/phd/Olfaction/MoLFormer_N2024/utils/custom_models.py:17\u001B[0m, in \u001B[0;36mLinearModelMultiLabelDeepchem.__init__\u001B[0;34m(self, model, class_imbalance_ratio, device_name, loss_aggr_type, mode, optimizer_name, learning_rate, batch_size)\u001B[0m\n\u001B[1;32m     15\u001B[0m             output_types: List \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprediction\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     16\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 17\u001B[0m             loss \u001B[38;5;241m=\u001B[39m \u001B[43mCustomMultiLabelBCEWitLogitsLoss\u001B[49m(\n\u001B[1;32m     18\u001B[0m                 class_imbalance_ratio\u001B[38;5;241m=\u001B[39mclass_imbalance_ratio,\n\u001B[1;32m     19\u001B[0m                 loss_aggr_type\u001B[38;5;241m=\u001B[39mloss_aggr_type,\n\u001B[1;32m     20\u001B[0m                 device\u001B[38;5;241m=\u001B[39mdevice_name)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# When predict() is called, only the first output (the probabilities) will be returned. But during training, it is the second output (the logits) that will be passed to the loss function.\u001B[39;00m\n\u001B[1;32m     23\u001B[0m             output_types \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprediction\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'CustomMultiLabelBCEWitLogitsLoss' is not defined"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Similarity Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Statistics"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:04:37.367616Z",
     "start_time": "2024-06-06T12:04:37.367363Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ravia_mean=df_ravia_similarity_mols['nonStereoSMILES'].apply(len).mean()\n",
    "# ravia_std=df_ravia_similarity_mols['nonStereoSMILES'].apply(len).std()\n",
    "# ravia_max=df_ravia_similarity_mols['nonStereoSMILES'].apply(len).max()\n",
    "# ravia_min=df_ravia_similarity_mols['nonStereoSMILES'].apply(len).min()\n",
    "# print(ravia_min, ravia_max, ravia_mean, ravia_std)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ravia2020 similarity MoLFormer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_ravia_similarity_mols,df_ravia_similarity_mols_embeddings_original,df_ravia_similarity_mols_layers_original\\\n",
    ",df_ravia_similarity_mols_embeddings,df_ravia_similarity_mols_embeddings_zscored,\\\n",
    "df_ravia_similarity_mols_layers,df_ravia_similarity_mols_layers_zscored,df_ravia_similarity_mols_embeddings_linear\\\n",
    ",df_ravia_similarity_mols_embeddings_linear_zscored=prepare_ravia_similarity_mols2(df_ravia_similarity_mean,modeldeepchem_gslf,lm,tokenizer)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "cosine_sim_df_ravia_similarity_mols_embeddings,cosine_sim_df_ravia_similarity_mols_embeddings_zscored,cosine_sim_df_ravia_similarity_mols_layers,cosine_sim_df_ravia_similarity_mols_layers_zscored,cosine_sim_df_ravia_similarity_mols_embeddings_linear,cosine_sim_df_ravia_similarity_mols_embeddings_linear_zscored\\\n",
    "=cosine_sim_helper(df_ravia_similarity_mols_embeddings,df_ravia_similarity_mols_embeddings_zscored,df_ravia_similarity_mols_layers,df_ravia_similarity_mols_layers_zscored,df_ravia_similarity_mols_embeddings_linear,df_ravia_similarity_mols_embeddings_linear_zscored)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ravia2020 similarity OpenPom"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "input_file_pom='/local_storage/datasets/farzaneh/alignment_olfaction_datasets/curated_datasets/embeddings/pom/ravia_pom_embeddings_Apr17.csv'\n",
    "\n",
    "df_ravia_similarity_mols_pom,df_ravia_similarity_mols_embeddings_original_pom\\\n",
    ",df_ravia_similarity_mols_embeddings_pom,df_ravia_similarity_mols_embeddings_zscored_pom\\\n",
    "=prepare_ravia_similarity_mols_mixture(input_file_pom, df_ravia_similarity_mean,modeldeepchem_gslf)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cosine_sim_df_ravia_similarity_mols_embeddings_pom,cosine_sim_df_ravia_similarity_mols_embeddings_zscored_pom\\\n",
    "=cosine_sim_helper_mixture(df_ravia_similarity_mols_embeddings_pom,df_ravia_similarity_mols_embeddings_zscored_pom)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ravia2020 similarity DAM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# df_mean=df_ravia_similarity_mean\n",
    "\n",
    "\n",
    "# df_mean_mols1 = df_mean[['Stimulus 1-IsomericSMILES','Stimulus 1-nonStereoSMILES','CID Stimulus 1']].drop_duplicates().reset_index(drop=True)\n",
    "# df_mean_mols2 = df_mean[['Stimulus 2-IsomericSMILES','Stimulus 2-nonStereoSMILES','CID Stimulus 2']].drop_duplicates().reset_index(drop=True).rename(columns={'Stimulus 2-nonStereoSMILES': 'Stimulus 1-nonStereoSMILES','Stimulus 2-IsomericSMILES':'Stimulus 1-IsomericSMILES', 'CID Stimulus 2': 'CID Stimulus 1' })\n",
    "# df_mols= pd.concat([df_mean_mols1, df_mean_mols2], ignore_index=True, axis=0).reset_index(drop=True)\n",
    "# df_mols = df_mols.rename(columns={'Stimulus 1-IsomericSMILES': 'IsomericSMILES','Stimulus 1-nonStereoSMILES':'nonStereoSMILES', 'CID Stimulus 1': 'CID' })\n",
    "# df_mols=df_mols.drop_duplicates().reset_index(drop=True)\n",
    "# # df_snitz_mols.to_csv('df_snitz_mols.csv')  \n",
    "# mol_type=\"nonStereoSMILES\"\n",
    "\n",
    "\n",
    "\n",
    "# ds_alva = pd.read_csv(input_file_alva)\n",
    "\n",
    "\n",
    "# chemical_features_r=[\"nCIR\",\n",
    "#                  \"ZM1\", \n",
    "#                  \"GNar\", \n",
    "#                  \"S1K\", \n",
    "#                  \"piPC08\",\n",
    "#                  \"MATS1v\",\n",
    "#                  \"MATS7v\",\n",
    "#                  \"GATS1v\", \n",
    "#                  \"Eig05_AEA(bo)\", \n",
    "#                  \"SM02_AEA(bo)\",\n",
    "#                  \"SM03_AEA(dm)\",\n",
    "#                  \"SM10_AEA(dm)\",\n",
    "#                  \"SM13_AEA(dm)\",\n",
    "#                   \"SpMin3_Bh(v)\",\n",
    "#                  \"RDF035v\",\n",
    "#                  \"G1m\",\n",
    "#                  \"G1v\",\n",
    "#                  \"G1e\",\n",
    "#                  \"G3s\",\n",
    "#                  \"R8u+\",\n",
    "#                  \"nRCOSR\"]\n",
    "# nonStereoSMILE = list(map(lambda x: \"nonStereoSMILES___\" + x, chemical_features_r))\n",
    "# # IsomericSMILES = list(map(lambda x: \"IsomericSMILES___\" + x, chemical_features_r))\n",
    "# selected_features = nonStereoSMILE\n",
    "# features= ['CID','nonStereoSMILES']+selected_features\n",
    "# # print(\"cc1\", ds_alva.columns.values.tolist())\n",
    "# ds_alva= ds_alva.rename(columns={\"cid\":\"CID\"})\n",
    "# # print(\"cc2\", ds_alva.columns.values.tolist())\n",
    "# ds_alva_selected = ds_alva[features]\n",
    "# ds_alva_selected = ds_alva_selected.fillna(0)\n",
    "# ds_alva_selected['embeddings'] = ds_alva_selected[selected_features].values.tolist()\n",
    "# df_mols\n",
    "\n",
    "# df_embeddigs = select_features(input_file_embeddings)[['embeddings','CID']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# def sum_embeddings(cid_list, df_embeddings):\n",
    "#     embedding_sum = np.zeros(len(df_embeddings.iloc[0]['embeddings']))\n",
    "#     for cid in cid_list:\n",
    "#         if cid in df_embeddings['CID'].values:\n",
    "#             embedding_sum += df_embeddings.loc[df_embeddings['CID'] == cid, 'embeddings'].values[0]\n",
    "#     return embedding_sum"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# def extract_embeddings(cid, df_embeddings):\n",
    "#     embedding_sum = np.zeros(len(df_embeddings.iloc[0]['embeddings']))\n",
    "#     # for cid in cid_list:\n",
    "#     if cid in df_embeddings['CID'].values:\n",
    "#         print(cid)\n",
    "#         # embedding_sum += df_embeddings.loc[df_embeddings['CID'] == cid, 'embeddings'].values[0]\n",
    "#     return embedding_sum"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# df_mols['Stimulus Embedding Sum'] = df_mols['CID'].apply(lambda x: sum_embeddings(list(map(int, x.split(';'))), ds_alva_selected))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "input_file_alva='/local_storage/datasets/farzaneh/alignment_olfaction_datasets/curated_datasets/alva/ravia_molecules_alva_17Apr.csv'\n",
    "\n",
    "df_ravia_similarity_mols_alva,df_ravia_similarity_mols_embeddings_original_alva\\\n",
    ",df_ravia_similarity_mols_embeddings_alva,df_ravia_similarity_mols_embeddings_zscored_alva\\\n",
    "=prepare_mols_DAM(input_file_alva,df_ravia_similarity_mean,modeldeepchem_gslf)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cosine_sim_df_ravia_similarity_mols_embeddings_alva,cosine_sim_df_ravia_similarity_mols_embeddings_zscored_alva\\\n",
    "=cosine_sim_helper_mixture(df_ravia_similarity_mols_embeddings_alva,df_ravia_similarity_mols_embeddings_zscored_alva)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snitz 2013 MoLFromer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# df_snitz_mols['nonStereoSMILES']\n",
    "# snitz_mean=df_snitz_mols['nonStereoSMILES'].apply(len).mean()\n",
    "# snitz_std=df_snitz_mols['nonStereoSMILES'].apply(len).std()\n",
    "# snitz_max=df_snitz_mols['nonStereoSMILES'].apply(len).max()\n",
    "# snitz_min=df_snitz_mols['nonStereoSMILES'].apply(len).min()\n",
    "# print(snitz_min, snitz_max, snitz_mean, snitz_std)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_snitz_mols,df_snitz_mols_embeddings_original,df_snitz_mols_layers_original,\\\n",
    "df_snitz_mols_embeddings,df_snitz_mols_embeddings_zscored,\\\n",
    "df_snitz_mols_layers,df_snitz_mols_layers_zscored,df_snitz_mols_embeddings_linear,\\\n",
    "df_snitz_mols_embeddings_linear_zscored=prepare_snitz_mols(df_snitz_mean,modeldeepchem_gslf,lm,tokenizer)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# df_snitz_mols_embeddings_linear"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "cosine_sim_df_snitz_mols_embeddings,cosine_sim_df_snitz_mols_embeddings_zscored,cosine_sim_df_snitz_mols_layers,cosine_sim_df_snitz_mols_layers_zscored,cosine_sim_df_snitz_mols_embeddings_linear,cosine_sim_df_snitz_mols_embeddings_linear_zscored \\\n",
    "=cosine_sim_helper(df_snitz_mols_embeddings,df_snitz_mols_embeddings_zscored,df_snitz_mols_layers,df_snitz_mols_layers_zscored,df_snitz_mols_embeddings_linear,df_snitz_mols_embeddings_linear_zscored)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snitz 2013 OpenPom"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "input_file_pom_snitz='/local_storage/datasets/farzaneh/alignment_olfaction_datasets/curated_datasets/embeddings/pom/snitz_pom_embeddings_Apr17.csv'\n",
    "# pd.read_csv(input_file_pom_snitz)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_snitz_mols_pom,df_snitz_mols_embeddings_original_pom,df_snitz_mols_embeddings_pom,df_snitz_mols_embeddings_zscored_pom=prepare_mols_other(input_file_pom_snitz, df_snitz_mean,modeldeepchem_gslf)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# df_snitz_mols_embeddings_pom.CID.values.tolist()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "# cosine_sim_df_snitz_mols_embeddings_pom,cosine_sim_df_snitz_mols_embeddings_zscored_pom,cosine_sim_df_snitz_mols_layers,cosine_sim_df_snitz_mols_layers_zscored,cosine_sim_df_snitz_mols_embeddings_linear,cosine_sim_df_snitz_mols_embeddings_linear_zscored \\\n",
    "# =cosine_sim_helper(df_snitz_mols_embeddings,df_snitz_mols_embeddings_zscored,df_snitz_mols_layers,df_snitz_mols_layers_zscored,df_snitz_mols_embeddings_linear,df_snitz_mols_embeddings_linear_zscored)\n",
    "\n",
    "\n",
    "cosine_sim_df_snitz_mols_embeddings_pom,cosine_sim_df_snitz_mols_embeddings_zscored_pom\\\n",
    "=cosine_sim_helper_mixture(df_snitz_mols_embeddings_pom,df_snitz_mols_embeddings_zscored_pom)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# df_snitz_mols_embeddings_pom"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snitz 2013 Alva"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "input_file_alva='/local_storage/datasets/farzaneh/alignment_olfaction_datasets/curated_datasets/alva/snitz_molecules_alva_17Apr.csv'\n",
    "\n",
    "df_snitz_mols_alva,df_snitz_mols_embeddings_original_alva\\\n",
    ",df_snitz_mols_embeddings_alva,df_snitz_mols_embeddings_zscored_alva\\\n",
    "=prepare_mols_DAM(input_file_alva,df_snitz_mean,modeldeepchem_gslf,sep=',')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cosine_sim_df_snitz_mols_embeddings_alva,cosine_sim_df_snitz_mols_embeddings_zscored_alva\\\n",
    "=cosine_sim_helper_mixture(df_snitz_mols_embeddings_alva,df_snitz_mols_embeddings_zscored_alva)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goodscent - Leffignwell"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_gslf_mols,df_gslf_mols_embeddings_original,df_gslf_mols_layers_original,df_gslf_mols_embeddings,df_gslf_mols_embeddings_zscored,df_gslf_mols_layers,df_gslf_mols_layers_zscored,df_gslf_mols_embeddings_linear,df_gslf_mols_embeddings_linear_zscored=prepare_goodscentleffignwell_mols(modeldeepchem_gslf,lm,tokenizer)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# df_snitz_mols['nonStereoSMILES']\n",
    "gslf_mean=df_gslf_mols['nonStereoSMILES'].apply(len).mean()\n",
    "gslf_std=df_gslf_mols['nonStereoSMILES'].apply(len).std()\n",
    "gslf_max=df_gslf_mols['nonStereoSMILES'].apply(len).max()\n",
    "gslf_min=df_gslf_mols['nonStereoSMILES'].apply(len).min()\n",
    "print(gslf_min, gslf_max, gslf_mean, gslf_std)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "  \n",
    "# TASKS = [\n",
    "# 'alcoholic', 'aldehydic', 'alliaceous', 'almond', 'amber', 'animal',\n",
    "# 'anisic', 'apple', 'apricot', 'aromatic', 'balsamic', 'banana', 'beefy',\n",
    "# 'bergamot', 'berry', 'bitter', 'black currant', 'brandy', 'burnt',\n",
    "# 'buttery', 'cabbage', 'camphoreous', 'caramellic', 'cedar', 'celery',\n",
    "# 'chamomile', 'cheesy', 'cherry', 'chocolate', 'cinnamon', 'citrus', 'clean',\n",
    "# 'clove', 'cocoa', 'coconut', 'coffee', 'cognac', 'cooked', 'cooling',\n",
    "# 'cortex', 'coumarinic', 'creamy', 'cucumber', 'dairy', 'dry', 'earthy',\n",
    "# 'ethereal', 'fatty', 'fermented', 'fishy', 'floral', 'fresh', 'fruit skin',\n",
    "# 'fruity', 'garlic', 'gassy', 'geranium', 'grape', 'grapefruit', 'grassy',\n",
    "# 'green', 'hawthorn', 'hay', 'hazelnut', 'herbal', 'honey', 'hyacinth',\n",
    "# 'jasmin', 'juicy', 'ketonic', 'lactonic', 'lavender', 'leafy', 'leathery',\n",
    "# 'lemon', 'lily', 'malty', 'meaty', 'medicinal', 'melon', 'metallic',\n",
    "# 'milky', 'mint', 'muguet', 'mushroom', 'musk', 'musty', 'natural', 'nutty',\n",
    "# 'odorless', 'oily', 'onion', 'orange', 'orangeflower', 'orris', 'ozone',\n",
    "# 'peach', 'pear', 'phenolic', 'pine', 'pineapple', 'plum', 'popcorn',\n",
    "# 'potato', 'powdery', 'pungent', 'radish', 'raspberry', 'ripe', 'roasted',\n",
    "# 'rose', 'rummy', 'sandalwood', 'savory', 'sharp', 'smoky', 'soapy',\n",
    "# 'solvent', 'sour', 'spicy', 'strawberry', 'sulfurous', 'sweaty', 'sweet',\n",
    "# 'tea', 'terpenic', 'tobacco', 'tomato', 'tropical', 'vanilla', 'vegetable',\n",
    "# 'vetiver', 'violet', 'warm', 'waxy', 'weedy', 'winey', 'woody'\n",
    "# ]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "input_embeddings='/local_storage/datasets/farzaneh/alignment_olfaction_datasets/curated_datasets/embeddings/pom/gslf_pom_embeddings_Apr17.csv'\n",
    "df_gslf_pom = pd.read_csv(input_embeddings, converters={'embeddings': pd.eval , \"y\": pd.eval})\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# df_gslf_mols_embeddings_zscored.to_csv('df_gslf_mols_embeddings_zscored.csv', index=False)\n",
    "# df_gslf_mols.to_csv('df_gslf_mols.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def pom_frame(pom_embeds, y, dir,required_desc,title,size1,size2,size3 ):\n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.despine()\n",
    "\n",
    "    # pom_embeds = model.predict_embedding(dataset)\n",
    "    # y_preds = model.predict(dataset)\n",
    "    # required_desc = list(dataset.tasks)\n",
    "    type1 = {'floral': '#F3F1F7', 'subs': {'muguet': '#FAD7E6', 'lavender': '#8883BE', 'jasmin': '#BD81B7'}}\n",
    "    type2 = {'meaty': '#F5EBE8', 'subs': {'savory': '#FBB360', 'beefy': '#7B382A', 'roasted': '#F7A69E'}}\n",
    "    type3 = {'ethereal': '#F2F6EC', 'subs': {'cognac': '#BCE2D2', 'fermented': '#79944F', 'alcoholic': '#C2DA8F'}}\n",
    "        \n",
    "    # Assuming you have your features in the 'features' array\n",
    "    pca = PCA(n_components=2, iterated_power=10)  # You can choose the number of components you want (e.g., 2 for 2D visualization)\n",
    "    reduced_features = pca.fit_transform(pom_embeds) # try different variations\n",
    "\n",
    "    variance_explained = pca.explained_variance_ratio_\n",
    "\n",
    "    # Variance explained by PC1 and PC2\n",
    "    variance_pc1 = variance_explained[0]\n",
    "    variance_pc2 = variance_explained[1]\n",
    "\n",
    "    # if is_preds:\n",
    "    #     y = np.where(y_preds>threshold, 1.0, 0.0) # try quartile range (or rank)\n",
    "    # else:\n",
    "    #     y = dataset.y\n",
    "\n",
    "    # Generate grid points to evaluate the KDE on (try kernel convolution)\n",
    "    x_grid, y_grid = np.meshgrid(np.linspace(reduced_features[:, 0].min(), reduced_features[:, 0].max(), 500),\n",
    "                                 np.linspace(reduced_features[:, 1].min(), reduced_features[:, 1].max(), 500))\n",
    "    grid_points = np.vstack([x_grid.ravel(), y_grid.ravel()])\n",
    "    def get_kde_values(label):\n",
    "        plot_idx = required_desc.index(label)\n",
    "        # print(y[:, plot_idx])\n",
    "        label_indices = np.where(y[:, plot_idx] == 1)[0]\n",
    "        kde_label = gaussian_kde(reduced_features[label_indices].T)\n",
    "        kde_values_label = kde_label(grid_points)\n",
    "        kde_values_label = kde_values_label.reshape(x_grid.shape)\n",
    "        return kde_values_label\n",
    "    \n",
    "    def plot_contours(type_dictionary, bbox_to_anchor):\n",
    "        main_label = list(type_dictionary.keys())[0]\n",
    "        plt.contourf(x_grid, y_grid, get_kde_values(main_label), levels=1, colors=['#00000000',type_dictionary[main_label],type_dictionary[main_label]])\n",
    "        axes = plt.gca() #Getting the current axis\n",
    "\n",
    "        axes.spines['top'].set_visible(False)\n",
    "        axes.spines['right'].set_visible(False)\n",
    "        legend_elements = []\n",
    "        for label, color in type_dictionary['subs'].items():\n",
    "            plt.contour(x_grid, y_grid, get_kde_values(label), levels=1, colors=color, linewidths=2)\n",
    "            legend_elements.append(Patch(facecolor=color, label=label))\n",
    "        legend = plt.legend(handles=legend_elements, title=main_label, bbox_to_anchor=bbox_to_anchor,prop={'size': 30})\n",
    "        legend.get_frame().set_facecolor(type_dictionary[main_label])\n",
    "        plt.gca().add_artist(legend)\n",
    "\n",
    "    fig=plt.figure(figsize=(15, 15),dpi=700)\n",
    "    # ax.spines[['right', 'top']].set_visible(False)\n",
    "    # plt.title('KDE Density Estimation with Contours in Reduced Space')\n",
    "    # plt.xlabel(f'Principal Component 1 ({round(variance_pc1*100, ndigits=2)}%)')\n",
    "    # plt.ylabel(f'Principal Component 2 ({round(variance_pc2*100, ndigits=2)}%)')\n",
    "    plt.xlabel('Principal Component 1',fontsize=35)\n",
    "    plt.ylabel('Principal Component 2',fontsize=35)\n",
    "    plot_contours(type_dictionary=type1, bbox_to_anchor = size1)\n",
    "    plot_contours(type_dictionary=type2, bbox_to_anchor = size2)\n",
    "    plot_contours(type_dictionary=type3, bbox_to_anchor = size3)\n",
    "    # plt.colorbar(label='Density')\n",
    "    # plt.show()\n",
    "    # png_file = os.path.join(dir, 'pom_frame.png')\n",
    "    # plt.savefig(png_file)\n",
    "    plt.savefig(\"figs/realign_islands\"+title+\".svg\")\n",
    "    plt.savefig(\"figs/realign_islands\"+title+\".pdf\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "# fig, axes = plt.subplots(1, 4, sharex=True, figsize=(16,8))\n",
    "\n",
    "# type1 = {'floral': '#F3F1F7', 'subs': {'muguet': '#FAD7E6', 'lavender': '#8883BE', 'jasmin': '#BD81B7'}}\n",
    "size1 = (0.3, 0.28)\n",
    "\n",
    "# type2 = {'meaty': '#F5EBE8', 'subs': {'savory': '#FBB360', 'beefy': '#7B382A', 'roasted': '#F7A69E'}}\n",
    "size2 = (0.6, 1)\n",
    "\n",
    "# type3 = {'ethereal': '#F2F6EC', 'subs': {'cognac': '#BCE2D2', 'fermented': '#79944F', 'alcoholic': '#C2DA8F'}}\n",
    "size3 = (1, 0.35)\n",
    "plt.rcParams[\"font.size\"] = 35\n",
    "pom_frame(np.asarray(df_gslf_mols_embeddings_zscored['Combined'].values.tolist()),np.asarray(df_gslf_mols.y.values.tolist()), \"/kaggle/working/\", gs_lf_tasks,\"2\",size1,size2,size3)\n",
    "# pom_frame(np.asarray(df_gslf_pom['embeddings'].values.tolist()),np.asarray(df_gslf_pom.y.values.tolist()), \"/kaggle/working/\", TASKS,\"1\",size1,size2,size3)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "# type1 = {'floral': '#F3F1F7', 'subs': {'muguet': '#FAD7E6', 'lavender': '#8883BE', 'jasmin': '#BD81B7'}}\n",
    "size1 = (0.3,0.86)\n",
    "\n",
    "# type2 = {'meaty': '#F5EBE8', 'subs': {'savory': '#FBB360', 'beefy': '#7B382A', 'roasted': '#F7A69E'}}\n",
    "size2 = (0.9, .7)\n",
    "\n",
    "# type3 = {'ethereal': '#F2F6EC', 'subs': {'cognac': '#BCE2D2', 'fermented': '#79944F', 'alcoholic': '#C2DA8F'}}\n",
    "size3 = (0.3, 0.2)\n",
    "\n",
    "\n",
    "\n",
    "# type1 = {'floral': '#F3F1F7', 'subs': {'muguet': '#FAD7E6', 'lavender': '#8883BE', 'jasmin': '#BD81B7'}}\n",
    "size1 = (0.8, 0.4)\n",
    "\n",
    "# type2 = {'meaty': '#F5EBE8', 'subs': {'savory': '#FBB360', 'beefy': '#7B382A', 'roasted': '#F7A69E'}}\n",
    "size2 = (0.9, 1.01)\n",
    "\n",
    "# type3 = {'ethereal': '#F2F6EC', 'subs': {'cognac': '#BCE2D2', 'fermented': '#79944F', 'alcoholic': '#C2DA8F'}}\n",
    "size3 = (0.4, 1.02)\n",
    "\n",
    "\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 35\n",
    "pom_frame(np.asarray(df_gslf_pom['embeddings'].values.tolist()),np.asarray(df_gslf_pom.y.values.tolist()), \"/kaggle/working/\", gs_lf_tasks,\"1\",size1,size2,size3)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "corr_last_ravia_similarity,corr_last_ravia_similarity_pvalue,corr_layers_ravia_similarity,corr_layers_ravia_similarity_pvalue=correlation_helper(df_ravia_similarity_mean_pivoted,cosine_sim_df_ravia_similarity_mols_embeddings_zscored,cosine_sim_df_ravia_similarity_mols_layers_zscored,equalize_size=True)\n",
    "corr_last_linear_ravia_similarity,corr_last_linear_ravia_similarity_pvalue,corr_layers_ravia_similarity,corr_layers_ravia_similarity_pvalue=correlation_helper(df_ravia_similarity_mean_pivoted,cosine_sim_df_ravia_similarity_mols_embeddings_linear_zscored,cosine_sim_df_ravia_similarity_mols_layers_zscored,equalize_size=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "# corr_last_keller,corr_last_keller_pvalue,corr_layers_keller,corr_layers_keller_pvalue=correlation_helper(cosine_sim_df_keller_zscored,cosine_sim_df_keller_mols_embeddings_zscored,cosine_sim_df_keller_mols_layers_zscored,equalize_size=True)\n",
    "# corr_last_linear_keller,corr_last_linear_keller_pvalue,corr_layers_keller,corr_layers_keller_pvalue=correlation_helper(cosine_sim_df_keller_zscored,cosine_sim_df_keller_mols_embeddings_linear_zscored,cosine_sim_df_keller_mols_layers_zscored,equalize_size=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "corr_last_ravia_similarity_pom,corr_last_ravia_similarity_pvalue_pom=correlation_helper_mixture(df_ravia_similarity_mean_pivoted,cosine_sim_df_ravia_similarity_mols_embeddings_zscored_pom,equalize_size=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "corr_last_ravia_similarity_alva,corr_last_ravia_similarity_pvalue_alva=correlation_helper_mixture(df_ravia_similarity_mean_pivoted,cosine_sim_df_ravia_similarity_mols_embeddings_zscored_alva,equalize_size=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "corr_last_snitz_pom,corr_last_snitz_pvalue_pom=correlation_helper_mixture(df_snitz_mean_pivoted,cosine_sim_df_snitz_mols_embeddings_zscored_pom,equalize_size=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "corr_last_snitz_alva,corr_last_snitz_pvalue_alva=correlation_helper_mixture(df_snitz_mean_pivoted,cosine_sim_df_snitz_mols_embeddings_zscored_alva,equalize_size=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "corr_last_snitz,corr_last_snitz_pvalue,corr_layers_snitz,corr_layers_snitz_pvalue=correlation_helper(df_snitz_mean_pivoted,cosine_sim_df_snitz_mols_embeddings_zscored,cosine_sim_df_snitz_mols_layers_zscored,equalize_size=True)\n",
    "corr_last_linear_snitz,corr_last_linear_snitz_pvalue,corr_layers_snitz,corr_layers_snitz_pvalue=correlation_helper(df_snitz_mean_pivoted,cosine_sim_df_snitz_mols_embeddings_linear_zscored,cosine_sim_df_snitz_mols_layers_zscored,equalize_size=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(corr_last_linear_snitz)\n",
    "print(corr_last_linear_snitz_pvalue)\n",
    "print(corr_last_linear_ravia_similarity)\n",
    "print(corr_last_linear_ravia_similarity_pvalue)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "corr_last_ravia_similarity_pom"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "corr_last_ravia_similarity"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "def plot_bars(data,title,filename):\n",
    "\n",
    "    df_corrs=pd.DataFrame.from_dict(data, orient='index',\n",
    "                           columns=['Dataset','type', 'Correlation'])\n",
    "    sns.set_style(\"white\")\n",
    "    fig, ax = plt.subplots(figsize=(8,8)\n",
    "                           # ,constrained_layout = True\n",
    "                          )\n",
    "    # sns.set_style(\"whitegrid\")\n",
    "    # sns.color_palette(\"tab10\")\n",
    "    sns.color_palette(\"hls\", 4)\n",
    "    palette=[ \"#91bfdb\",\n",
    "                \"#003f5c\",\n",
    "                 # \"#d73027\",\n",
    "                 # \"#fc8d59\",\n",
    "                 # \"#ffda33\",\n",
    "                \n",
    "                # , \"#4575b4\"\n",
    "    ]\n",
    "    \n",
    "    palette=['#4d79a4','#ecc947','#b07aa0']\n",
    "    \n",
    "    # plt.subplots_adjust(bottom=0.3)\n",
    "    g=sns.barplot(df_corrs, x=\"Dataset\", y=\"Correlation\", hue= \"type\",width=0.4,palette=palette)\n",
    "    # for i in ax.containers:\n",
    "    #     ax.bar_label(i,fmt=\"%2.2f\")\n",
    "    ax.legend().set_title(title)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.get_legend().remove()\n",
    "    fig.subplots_adjust(bottom=0.35,left=0.2)\n",
    "    fig.legend(handles, labels, ncol=3, columnspacing=0.8, prop={'size': 25}, handlelength=1.5, loc=\"lower center\",\n",
    "               borderpad=0.4,\n",
    "               \n",
    "               bbox_to_anchor=(0.54, 0.07), \n",
    "               \n",
    "               frameon=True, labelspacing=0.4,handletextpad=0.2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    # g.set_yticks([0.45,0.5,0.55,0.6,0.65,0.7]) # <--- set the ticks first\n",
    "    # g.set_yticklabels(['', '','', '','', ''])\n",
    "    \n",
    "    ax.set_ylabel('Correlation Coefficient')\n",
    "    \n",
    "    # plt.margins(x=0.5)\n",
    "    # fig.update_layout(bargap=0.1)\n",
    "    # ax.set_subtitle(\"Dataset\")  # Set title with numeric distance\n",
    "    # axes[0].set_title(\"Total Bill Distribution\", loc=(0.05, 0.9))  # Set title with numeric distance\n",
    "    \n",
    "    # ax.set_title('')\n",
    "    ax.xaxis.set_label_coords(0.5, -0.18)\n",
    "    # plt.tight_layout()\n",
    "#     g.set_yticks([0.45,0.5,0.55,0.6,0.65,0.7]) # <--- set the ticks first\n",
    "    \n",
    "#     g.set_yticklabels(['', '0.5','', '0.6','', '0.7'])\n",
    "#     g.set_ylim(0.45,0.7)\n",
    "    \n",
    "    plt.savefig(filename, \n",
    "                bbox_inches=\"tight\"\n",
    "               )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.rcParams[\"font.size\"] = 35\n",
    "data={\n",
    "    'row_1':  [ \"Snitz 2013\",\"MoLFormer\",corr_last_snitz],'row_2':[\"Ravia 2020\",\"MoLFormer\" ,corr_last_ravia_similarity],\n",
    "    'row_3':[\"Ravia 2020\",\"Open-POM\" ,corr_last_ravia_similarity_pom], 'row_4':[\"Snitz 2013\",\"Open-POM\" ,corr_last_snitz_pom],\n",
    "    'row_5':[\"Ravia 2020\",\"DAM\" ,corr_last_ravia_similarity_alva], 'row_6':[\"Snitz 2013\",\"DAM\" ,corr_last_snitz_alva],\n",
    "    \n",
    "    # , \"row_3\": [\"Keller 2016\",\"Raw Representations\",corr_last_keller],\n",
    "    # 'row_4':  [ \"Snitz 2013\",\"Transformed Representations\",corr_last_linear_snitz],'row_5':[\"Ravia 2020 \",\"Transformed Representations\" ,corr_last_linear_ravia_similarity] ,'row_3':[\"Ravia 2020 \",\"Raw Representations\" ,corr_last_ravia_similarity_pom\n",
    "    \n",
    "    # , \"row_6\": [\"Keller 2016\",\"Transformed Representations\",corr_last_linear_keller]\n",
    "\n",
    "     }\n",
    "plot_bars(data,\"perception\",\"figs/realign_correlations.pdf\")\n",
    "filename=\"figs/realign_correlations.pdf\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# df_corrs=pd.DataFrame.from_dict(data, orient='index',\n",
    "#                            columns=['Dataset','type', 'Correlation'])\n",
    "# sns.set_style(\"white\")\n",
    "# fig, ax = plt.subplots(figsize=(7.5, 7.5)\n",
    "#                        # ,constrained_layout = True\n",
    "#                       )\n",
    "# # sns.set_style(\"whitegrid\")\n",
    "# # sns.color_palette(\"tab10\")\n",
    "# sns.color_palette(\"hls\", 4)\n",
    "# palette=[ \"#91bfdb\",\n",
    "#             \"#003f5c\",\n",
    "#              # \"#d73027\",\n",
    "#              # \"#fc8d59\",\n",
    "#              # \"#ffda33\",\n",
    "            \n",
    "#             # , \"#4575b4\"\n",
    "# ]\n",
    "\n",
    "# palette=['#4d79a4','#ecc947','#b07aa0']\n",
    "\n",
    "# # plt.subplots_adjust(bottom=0.3)\n",
    "# g=sns.barplot(df_corrs, x=\"Dataset\", y=\"Correlation\", hue= \"type\",width=0.4,palette=palette)\n",
    "# # for i in ax.containers:\n",
    "# #     ax.bar_label(i,fmt=\"%2.2f\")\n",
    "# # ax.legend().set_title(title)\n",
    "# handles, labels = ax.get_legend_handles_labels()\n",
    "# ax.get_legend().remove()\n",
    "# fig.subplots_adjust(bottom=0.35,left=0.2)\n",
    "# fig.legend(handles, labels, ncol=1, columnspacing=1, prop={'size': 25}, handlelength=1.5, loc=\"lower center\",\n",
    "#            borderpad=0.3,\n",
    "           \n",
    "#            bbox_to_anchor=(0.54, 0.), \n",
    "           \n",
    "#            frameon=True, labelspacing=0.4,handletextpad=0.2)\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "\n",
    "# # g.set_yticks([0.45,0.5,0.55,0.6,0.65,0.7]) # <--- set the ticks first\n",
    "# # g.set_yticklabels(['', '','', '','', ''])\n",
    "\n",
    "# ax.set_ylabel('Correlation Coefficient')\n",
    "\n",
    "# # plt.margins(x=0.5)\n",
    "# # fig.update_layout(bargap=0.1)\n",
    "# # ax.set_subtitle(\"Dataset\")  # Set title with numeric distance\n",
    "# # axes[0].set_title(\"Total Bill Distribution\", loc=(0.05, 0.9))  # Set title with numeric distance\n",
    "\n",
    "# # ax.set_title('')\n",
    "# ax.xaxis.set_label_coords(0.5, -0.13)\n",
    "#     # plt.tight_layout()\n",
    "# #  g.set_yticks([0.45,0.5,0.55,0.6,0.65,0.7]) # <--- set the ticks first\n",
    "    \n",
    "# #  g.set_yticklabels(['', '0.5','', '0.6','', '0.7'])\n",
    "# #  g.set_ylim(0.45,0.7)\n",
    "    \n",
    "# plt.savefig(filename, \n",
    "#                 # bbox_inches=\"tight\"\n",
    "#                )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_lines(data,title,filename):\n",
    "    df_corrs=pd.DataFrame.from_dict(data, orient='index',\n",
    "                       columns=['Dataset', 'Correlation'])\n",
    "    df_corrs=df_corrs.explode('Correlation')\n",
    "    df_corrs['Layer'] = df_corrs.groupby(level=0).cumcount()\n",
    "    #alternative\n",
    "    #df['idx'] = df.groupby(df.index).cumcount()\n",
    "    df_corrs = df_corrs.reset_index(drop=True)\n",
    "    sns.set_style(\"white\")\n",
    "    # df[['0', '1','2', '3', '4', '5', '6', '7', '8', '9', '10', '11']] = df['All layers'].str.split(' ', expand=True)\n",
    "    fig, ax = plt.subplots(figsize=(10,10)\n",
    "                           # ,constrained_layout = True\n",
    "                          )\n",
    "    \n",
    "    \n",
    "    # sns.color_palette(\"tab10\")\n",
    "    sns.color_palette(\"hls\", 4)\n",
    "    palette=['#4d79a4','#ecc947','#b07aa0']\n",
    "    g=sns.lineplot(data=df_corrs, x=\"Layer\", y=\"Correlation\",hue=\"Dataset\",palette = palette, lw=7)\n",
    "    # sns.barplot(df_corrs, x=\"Dataset\", y=\"Correlation\", hue= \"Correlation\",width=0.2,legend=False,palette=sns.color_palette(\"Set2\",4))\n",
    "    \n",
    "    \n",
    "    ax.legend().set_title(title)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.get_legend().remove()\n",
    "     # axes = plt.gca() #Getting the current axis\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    #56c4c0fb\n",
    "    \n",
    "    fig.subplots_adjust(bottom=0.35,left=0.2)\n",
    "    fig.legend(handles, labels, ncol=3, columnspacing=1, prop={'size': 25}, handlelength=1.5, loc=\"lower center\",\n",
    "               borderpad=0.4,\n",
    "               \n",
    "               bbox_to_anchor=(0.54, 0.07), \n",
    "               \n",
    "               frameon=True, labelspacing=0.4,handletextpad=0.2)\n",
    "    g.set_xticks([0,2,4,6,8,10]) # <--- set the ticks first\n",
    "    g.set_xticklabels(['1', '3', '5', '7', '9', '11'])\n",
    "    \n",
    "    # g.set_yticks([0.45,0.5,0.55,0.6,0.65,0.7]) # <--- set the ticks first\n",
    "    # g.set_yticklabels(['', '0.5','', '0.6','', '0.7'])\n",
    "    \n",
    "    # g.set_yticks([0.45,0.5,0.55,0.6,0.65,0.7]) # <--- set the ticks first\n",
    "    # g.set_yticklabels(['', '0.5','', '0.6','', '0.7'])\n",
    "    # g.set_ylim(0.45,0.7)\n",
    "    \n",
    "    g.set_xlim(0,11)\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('Model Layer')\n",
    "    # plt.margins(0,-0.16)\n",
    "    ax.xaxis.set_label_coords(0.5, -0.18)\n",
    "    \n",
    "    # plt.tight_layout()\n",
    "    plt.savefig(filename\n",
    "                , bbox_inches=\"tight\"\n",
    "               \n",
    "               )\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.rcParams[\"font.size\"] = 35   \n",
    "data={'row_1':  [ \"Snitz\",corr_layers_snitz],'row_2':[\"Ravia\" ,corr_layers_ravia_similarity] \n",
    "     # , \"row_4\": [\"Keller 2016\",corr_layers_keller]\n",
    "     }\n",
    "plot_lines(data,\"perception\",\"figs/realign_layers.pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Molecular Representations and fMRI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagar"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def prepare_sagar_fmri_mols():\n",
    "    \n",
    "    input_file_sagar = '/local_storage/datasets/farzaneh/openpom/data/curated_datasets/curated_sagar_flattened_fmri_mols.csv'\n",
    "    df_sagar=pd.read_csv(input_file_sagar)\n",
    "    df_sagar = df_sagar.rename(columns={\"cid\":\"CID\"})\n",
    "    df_sagar = df_sagar.reset_index()\n",
    "    df_sagar_mols_embeddings_original,df_sagar_mols_layers_original,df_sagar_mols_embeddings,df_sagar_mols_embeddings_zscored,df_sagar_mols_layers,df_sagar_mols_layers_zscored,df_sagar_mols_embeddings_linear,df_sagar_mols_embeddings_linear_zscored=prepare_mols_helper(modeldeepchem_gslf,df_sagar,mol_type=\"nonStereoSMILES\",index=[\"CID\",\"subject\"])\n",
    "    return df_sagar,df_sagar_mols,df_sagar_mols_embeddings_original,df_sagar_mols_layers_original,df_sagar_mols_embeddings,df_sagar_mols_embeddings_zscored,df_sagar_mols_layers,df_sagar_mols_layers_zscored,df_sagar_mols_embeddings_linear,df_sagar_mols_embeddings_linear_zscored\n",
    "\n",
    "    \n",
    "    # return df_sagar\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_sagar,df_sagar_mols,df_sagar_mols_embeddings_original,df_sagar_mols_layers_original,df_sagar_mols_embeddings,df_sagar_mols_embeddings_zscored,df_sagar_mols_layers,df_sagar_mols_layers_zscored,df_sagar_mols_embeddings_linear,df_sagar_mols_embeddings_linear_zscored=prepare_sagar_fmri_mols()\n",
    "# df_mols_embeddings.head(5)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_sagar_fmri_molformer = pd.merge(df_sagar_mols_embeddings_zscored, df_sagar,  how='left', left_on=['subject','CID'], right_on = ['subject','CID'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def convert_fmri_data(data_list):\n",
    "    datas=[]\n",
    "    \n",
    "    for data in data_list:\n",
    "        array_str=data\n",
    "        array_str = array_str.replace(\"[array(\", \"\").replace(\"\\n\", \"\").replace(\")]\", \"\")\n",
    "        array_np = np.array(ast.literal_eval(array_str))\n",
    "        datas.append(array_np)\n",
    "    # datas.shape\n",
    "    return np.asarray(datas)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def convert_chemical_data(data_list):\n",
    "    datas=[]\n",
    "    \n",
    "    for data in data_list:\n",
    "        array_str=data\n",
    "        datas.append(array_str)\n",
    "    # datas.shape\n",
    "    return np.asarray(datas)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for subject in [1,2,3]:\n",
    "    for roi in ['PirF', 'PirT','AMY']:\n",
    "        selected_subject=df_sagar_fmri_molformer[(df_sagar_fmri_molformer['subject']==subject)][[roi,'CID','IsomericSMILES','nonStereoSMILES', 'Combined']]\n",
    "        fmri_data=selected_subject[roi]\n",
    "        chemical_data=selected_subject['Combined']\n",
    "        # print(fmri_data)\n",
    "        fmri_data=convert_fmri_data(fmri_data)\n",
    "        chemical_data=convert_chemical_data(chemical_data)\n",
    "        print(chemical_data.shape)\n",
    "        print(fmri_data.shape)\n",
    "        corrs, acc, acc_std, all_preds, all_test_data,pearson,res1=run_class_time_CV_fmri_crossval_ridge(chemical_data,fmri_data)\n",
    "        print(np.max(res1))\n",
    "        print(\"rr\",res1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# def prepare_mols_helper_backup(df_mols,mol_type=\"nonStereoSMILES\"):\n",
    "#     df_mols_layers=[]\n",
    "#     df_mols_layers_zscored=[]\n",
    "    \n",
    "#     #inference on molecules\n",
    "#     df_mols_embeddings_original, df_mols_layers_original=embed(lm,df_mols[mol_type], tokenizer, batch_size=64)\n",
    "    \n",
    "    \n",
    "        \n",
    "#     df_mols_embeddings=postproce_molembeddings(df_mols_embeddings_original,df_mols['CID'])\n",
    "    \n",
    "    \n",
    "#     df_mols_embeddings_diskdataset = dc.data.DiskDataset.from_numpy(df_mols_embeddings['Combined'].values.tolist())\n",
    "#     df_mols_embeddings_linear=modeldeepchem.predict_embedding(df_mols_embeddings_diskdataset)\n",
    "#     df_mols_embeddings_linear_torch=[torch.from_numpy(x.reshape(1,-1)) for x in df_mols_embeddings_linear]\n",
    "#     df_mols_embeddings_linear=postproce_molembeddings(df_mols_embeddings_linear_torch,df_mols['CID'])\n",
    "    \n",
    "    \n",
    "#      #z-score embeddings\n",
    "#     df_mols_embeddings_zscored = df_mols_embeddings.copy()\n",
    "#     scaled_features = StandardScaler().fit_transform(df_mols_embeddings_zscored.loc[:, 0:767].values.tolist())\n",
    "#     df_mols_embeddings_zscored.loc[:, 0:767] = pd.DataFrame(scaled_features, index=df_mols_embeddings_zscored.index, columns=df_mols_embeddings_zscored.columns[1:-1])\n",
    "#     df_mols_embeddings_zscored['Combined'] = df_mols_embeddings_zscored.loc[:, 0:767].values.tolist()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     #z-score linear embeddings\n",
    "#     df_mols_embeddings_linear_zscored = df_mols_embeddings_linear.copy()\n",
    "#     scaled_features = StandardScaler().fit_transform(df_mols_embeddings_linear_zscored.loc[:, 0:255].values.tolist())\n",
    "#     df_mols_embeddings_linear_zscored.loc[:, 0:255] = pd.DataFrame(scaled_features, index=df_mols_embeddings_linear_zscored.index, columns=df_mols_embeddings_linear_zscored.columns[1:-1])\n",
    "#     df_mols_embeddings_linear_zscored['Combined'] = df_mols_embeddings_linear_zscored.loc[:, 0:255].values.tolist()\n",
    "\n",
    "\n",
    "    \n",
    "#     for df_mols_layer in df_mols_layers_original:\n",
    "#         df_mols_layer=postproce_molembeddings(df_mols_layer,df_mols['CID'])\n",
    "#         df_mols_layers.append(df_mols_layer)\n",
    "#         # print(\"step2\")\n",
    "        \n",
    "#          #z-score embeddings\n",
    "#         df_mols_embeddings_zscored = df_mols_layer.copy()\n",
    "#         scaled_features = StandardScaler().fit_transform(df_mols_embeddings_zscored.loc[:, 0:767].values.tolist())\n",
    "#         df_mols_embeddings_zscored.loc[:, 0:767] = pd.DataFrame(scaled_features, index=df_mols_embeddings_zscored.index, columns=df_mols_embeddings_zscored.columns[1:-1])\n",
    "#         df_mols_embeddings_zscored['Combined'] = df_mols_embeddings_zscored.loc[:, 0:767].values.tolist()\n",
    "#         df_mols_layers_zscored.append(df_mols_embeddings_zscored)\n",
    "        \n",
    "    \n",
    "#     return df_mols_embeddings_original,df_mols_layers_original,df_mols_embeddings,df_mols_embeddings_zscored,df_mols_layers,df_mols_layers_zscored,df_mols_embeddings_linear,df_mols_embeddings_linear_zscored"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# def postproce_molembeddingss(embeddings,index):\n",
    "#     # molecules_embeddings_penultimate = torch.cat(embeddings)\n",
    "#     # molecules_embeddings_penultimate=torch.cat(molecules_embeddings_penultimate,index)\n",
    "#     # df_molecules_embeddings = pd.DataFrame(molecules_embeddings_penultimate, index=index)\n",
    "#     # df_molecules_embeddings['Combined'] = df_molecules_embeddings.loc[:, '0':'767'].values.tolist()\n",
    "#     # df_molecules_embeddings=df_molecules_embeddings.reset_index()\n",
    "#     # return(df_molecules_embeddings)\n",
    "#     molecules_embeddings_penultimate = torch.cat(embeddings)\n",
    "#     # print(\"sizeeee\",molecules_embeddings_penultimate.size())\n",
    "#     if index.ndim>1:\n",
    "#         columns_size= int(molecules_embeddings_penultimate.size()[1])\n",
    "#         # print(\"index\", index)\n",
    "        \n",
    "#         molecules_embeddings_penultimate = torch.cat(( torch.from_numpy( index.to_numpy()),molecules_embeddings_penultimate), dim=1)\n",
    "#         # print(\"mmmm\",molecules_embeddings_penultimate[0:4,0:4])\n",
    "#         df_molecules_embeddings = pd.DataFrame(molecules_embeddings_penultimate,columns=['CID','subject']+[str(i) for i in range(columns_size)])\n",
    "#         # print(\"ddd\",df_molecules_embeddings.columns.tolist())\n",
    "        \n",
    "        \n",
    "#         df_molecules_embeddings=df_molecules_embeddings.set_index(['CID','subject'])\n",
    "#         df_molecules_embeddings['Combined'] = df_molecules_embeddings.loc[:, '0':str(columns_size-1)].values.tolist()\n",
    "\n",
    "        \n",
    "#     else:\n",
    "#         df_molecules_embeddings = pd.DataFrame(molecules_embeddings_penultimate, index=index)\n",
    "#         df_molecules_embeddings['Combined'] = df_molecules_embeddings.loc[:, '0':'767'].values.tolist()\n",
    "#     df_molecules_embeddings=df_molecules_embeddings.reset_index()\n",
    "#     return df_molecules_embeddings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# def prepare_sagar_mols():\n",
    "#     df_sagar_mols = df_sagar.drop_duplicates('CID')\n",
    "#     print(df_sagar_mols.columns)\n",
    "#     df_sagar_mols_embeddings_original,df_sagar_mols_layers_original,df_sagar_mols_embeddings,df_sagar_mols_embeddings_zscored,df_sagar_mols_layers,df_sagar_mols_layers_zscored,df_sagar_mols_embeddings_linear,df_sagar_mols_embeddings_linear_zscored=prepare_mols_helper(df_sagar_mols,mol_type=\"nonStereoSMILES\")\n",
    "#     return df_sagar_mols,df_sagar_mols_embeddings_original,df_sagar_mols_layers_original,df_sagar_mols_embeddings,df_sagar_mols_embeddings_zscored,df_sagar_mols_layers,df_sagar_mols_layers_zscored,df_sagar_mols_embeddings_linear,df_sagar_mols_embeddings_linear_zscored\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# def prepare_mols_helper_changing(df_mols,mol_type=\"nonStereoSMILES\",index=\"CID\"):\n",
    "#     df_mols_layers=[]\n",
    "#     df_mols_layers_zscored=[]\n",
    "    \n",
    "#     #inference on molecules\n",
    "#     df_mols_embeddings_original, df_mols_layers_original=embed(lm,df_mols[mol_type], tokenizer, batch_size=64)\n",
    "    \n",
    "    \n",
    "        \n",
    "#     df_mols_embeddings=postproce_molembeddingss(df_mols_embeddings_original,df_mols[index])\n",
    "#     print(\"columns\",df_mols_embeddings.columns)\n",
    "\n",
    "    \n",
    "    \n",
    "#     df_mols_embeddings_diskdataset = dc.data.DiskDataset.from_numpy(df_mols_embeddings['Combined'].values.tolist())\n",
    "#     df_mols_embeddings_linear=modeldeepchem.predict_embedding(df_mols_embeddings_diskdataset)\n",
    "#     df_mols_embeddings_linear_torch=[torch.from_numpy(x.reshape(1,-1)) for x in df_mols_embeddings_linear]\n",
    "#     df_mols_embeddings_linear=postproce_molembeddingss(df_mols_embeddings_linear_torch,df_mols[index])\n",
    "    \n",
    "    \n",
    "#      #z-score embeddings\n",
    "#     df_mols_embeddings_zscored = df_mols_embeddings.copy()\n",
    "#     scaled_features = StandardScaler().fit_transform(df_mols_embeddings_zscored.loc[:, '0':'767'].values.tolist())\n",
    "#     df_mols_embeddings_zscored.loc[:, '0':'767'] = pd.DataFrame(scaled_features, index=df_mols_embeddings_zscored.index, columns=[str(i) for i in range(768)])\n",
    "#     df_mols_embeddings_zscored['Combined'] = df_mols_embeddings_zscored.loc[:, '0':'767'].values.tolist()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     #z-score linear embeddings\n",
    "#     df_mols_embeddings_linear_zscored = df_mols_embeddings_linear.copy()\n",
    "#     scaled_features = StandardScaler().fit_transform(df_mols_embeddings_linear_zscored.loc[:, '0':'255'].values.tolist())\n",
    "#     df_mols_embeddings_linear_zscored.loc[:, '0':'255'] = pd.DataFrame(scaled_features, index=df_mols_embeddings_linear_zscored.index, columns=[str(i) for i in range(256)])\n",
    "#     df_mols_embeddings_linear_zscored['Combined'] = df_mols_embeddings_linear_zscored.loc[:, '0':'255'].values.tolist()\n",
    "\n",
    "\n",
    "    \n",
    "#     for df_mols_layer in df_mols_layers_original:\n",
    "#         df_mols_layer=postproce_molembeddingss(df_mols_layer,df_mols[index])\n",
    "#         df_mols_layers.append(df_mols_layer)\n",
    "#         # print(\"step2\")\n",
    "        \n",
    "#          #z-score embeddings\n",
    "#         df_mols_embeddings_zscored = df_mols_layer.copy()\n",
    "#         scaled_features = StandardScaler().fit_transform(df_mols_embeddings_zscored.loc[:, '0':'767'].values.tolist())\n",
    "#         df_mols_embeddings_zscored.loc[:, '0':'767'] = pd.DataFrame(scaled_features, index=df_mols_embeddings_zscored.index, columns=[str(i) for i in range(768)])\n",
    "#         df_mols_embeddings_zscored['Combined'] = df_mols_embeddings_zscored.loc[:, '0':'767'].values.tolist()\n",
    "#         df_mols_layers_zscored.append(df_mols_embeddings_zscored)\n",
    "        \n",
    "    \n",
    "#     return df_mols_embeddings_original,df_mols_layers_original,df_mols_embeddings,df_mols_embeddings_zscored,df_mols_layers,df_mols_layers_zscored,df_mols_embeddings_linear,df_mols_embeddings_linear_zscored"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# df_sagar_mols,df_sagar_mols_embeddings_original,df_sagar_mols_layers_original,df_sagar_mols_embeddings,df_sagar_mols_embeddings_zscored,df_sagar_mols_layers,df_sagar_mols_layers_zscored,df_sagar_mols_embeddings_linear,df_sagar_mols_embeddings_linear_zscored=prepare_sagar_mols()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
